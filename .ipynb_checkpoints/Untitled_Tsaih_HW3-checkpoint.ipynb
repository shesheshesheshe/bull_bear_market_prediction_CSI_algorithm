{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input node, m = 32\n",
      "Number of hidden node, p = 21\n",
      "Number of inputs, q = 51\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import numpy as np\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "!rm -rf ./logs/ \n",
    "import sys\n",
    "\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "  inputSize = 32\n",
    "  hiddenSize = 21\n",
    "  dataVolume = 51\n",
    "  x_data = 2 * np.random.random_sample((dataVolume, inputSize)) -1\n",
    "  y_data = 2 * np.random.random_sample((dataVolume, 1)) -1\n",
    "  xs = tf.placeholder(tf.float32)\n",
    "  yc = tf.placeholder(tf.float32)\n",
    "\n",
    "print(\"Number of input node, m =\", inputSize)\n",
    "print(\"Number of hidden node, p =\", hiddenSize)\n",
    "print(\"Number of inputs, q =\", dataVolume)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs, input_size, output_size, activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([input_size, output_size]))\n",
    "    threshold = tf.Variable(tf.zeros([1, output_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + threshold\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs, Weights, threshold\n",
    "\n",
    "LearningRate = 0.01\n",
    "RegularizationTerm = 0.001\n",
    "LearningRateArr = []\n",
    "ErrorArr = []\n",
    "\n",
    "#Step 1\n",
    "HiddenLOutput, HWeights, HThreshold = add_layer(xs, inputSize, hiddenSize, activation_function = tf.tanh)\n",
    "OutputLOutput, OWeights, OThreshold = add_layer(HiddenLOutput, hiddenSize, 1, activation_function = None)\n",
    "\n",
    "\n",
    "#Forwarding (Activation Function & Regulation term)\n",
    "with tf.name_scope(\"loss\"):\n",
    "  LossFunction = tf.reduce_mean(tf.reduce_sum(tf.square(yc - OutputLOutput)\n",
    "                  , reduction_indices=[1])) + tf.math.multiply(RegularizationTerm\n",
    "                  , tf.reduce_sum(tf.square(OWeights)) + tf.reduce_sum(tf.square(HWeights)) + tf.reduce_sum(tf.square(HThreshold))+tf.reduce_sum(tf.square(OThreshold)))\n",
    "\n",
    "#Backwarding by Gradient\n",
    "#Set adjusted Learning Goal\n",
    "with tf.name_scope(\"train\"):\n",
    "  train = tf.train.GradientDescentOptimizer(LearningRate).minimize(LossFunction)\n",
    "\n",
    "#LTS\n",
    "residual = tf.square(yc - OutputLOutput)\n",
    "def lts(n, lts_x_error, x_data, y_data):\n",
    "    lts_x_data = []\n",
    "    lts_y_data = []\n",
    "    #index_list = []\n",
    "    for i in range(n):\n",
    "        index = np.where(lts_x_error == lts_x_error.min())\n",
    "        #index_list.append(index[0])\n",
    "        lts_x_error[index[0]] = lts_x_error.max() + 1\n",
    "        lts_x_data.extend(x_data[index[0]])\n",
    "        lts_y_data.extend(y_data[index[0]])\n",
    "    return lts_x_data, lts_y_data\n",
    "\n",
    "#Learning Goal\n",
    "LearningGoalFunction = tf.reduce_mean(tf.reduce_sum(tf.math.abs(yc - OutputLOutput), reduction_indices=[1]))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1 \n",
      "Initial model.\n",
      "Round: 2\n",
      "No out-lier.\n",
      "Round: 3\n",
      "No out-lier.\n",
      "Round: 4\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008543018419712434\n",
      "2 Keep learning at learning rate = 0.010251622103654922\n",
      "3 Fail: due to tiny learning rate( 0.007176135472558445 )\n",
      "Stop, Learning Goal = 0.113241106\n",
      "[[-0.32644463]\n",
      " [ 0.2047654 ]\n",
      " [ 0.83492565]\n",
      " [-0.759905  ]]\n",
      "Round: 5\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007176135472558445\n",
      "2 Fail: due to tiny learning rate( 0.008611362567070133 )\n",
      "Stop, Learning Goal = 0.16012016\n",
      "[[-0.3105913 ]\n",
      " [ 0.84816253]\n",
      " [ 0.1816369 ]\n",
      " [-0.6842607 ]\n",
      " [-0.47857913]]\n",
      "Round: 6\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008611362567070133\n",
      "2 Keep learning at learning rate = 0.01033363508048416\n",
      "3 Fail: due to tiny learning rate( 0.007233544556338911 )\n",
      "Stop, Learning Goal = 0.15780233\n",
      "[[-0.2833027 ]\n",
      " [ 0.8557447 ]\n",
      " [ 0.20186123]\n",
      " [-0.65112627]\n",
      " [-0.40312746]\n",
      " [ 0.4647232 ]]\n",
      "Round: 7\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007233544556338911\n",
      "2 Fail: due to tiny learning rate( 0.008680253467606694 )\n",
      "Stop, Learning Goal = 0.19623704\n",
      "[[ 0.8572055 ]\n",
      " [-0.2742735 ]\n",
      " [-0.64319247]\n",
      " [ 0.14236152]\n",
      " [-0.37542415]\n",
      " [ 0.54393727]\n",
      " [-0.52177966]]\n",
      "Round: 8\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008680253467606694\n",
      "2 Keep learning at learning rate = 0.010416304161128032\n",
      "3 Fail: due to tiny learning rate( 0.007291412912789622 )\n",
      "Stop, Learning Goal = 0.1986515\n",
      "[[ 0.11531645]\n",
      " [ 0.8630041 ]\n",
      " [-0.65245247]\n",
      " [-0.2753414 ]\n",
      " [-0.36207342]\n",
      " [-0.63312936]\n",
      " [ 0.5867727 ]\n",
      " [ 0.69084346]]\n",
      "Round: 9\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007291412912789622\n",
      "2 Fail: due to tiny learning rate( 0.008749695495347546 )\n",
      "Stop, Learning Goal = 0.19987284\n",
      "[[ 0.0858081 ]\n",
      " [ 0.88680106]\n",
      " [-0.30330628]\n",
      " [-0.70281583]\n",
      " [-0.34418994]\n",
      " [-0.7210192 ]\n",
      " [ 0.62367743]\n",
      " [ 0.4868725 ]\n",
      " [-0.6088452 ]]\n",
      "Round: 10\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008749695495347546\n",
      "2 Keep learning at learning rate = 0.010499634594417055\n",
      "3 Fail: due to tiny learning rate( 0.007349744216091938 )\n",
      "Stop, Learning Goal = 0.19441433\n",
      "[[ 0.89137006]\n",
      " [-0.3144846 ]\n",
      " [ 0.07415802]\n",
      " [-0.33737218]\n",
      " [-0.71316874]\n",
      " [-0.7644937 ]\n",
      " [ 0.44705582]\n",
      " [ 0.6593162 ]\n",
      " [-0.72749233]\n",
      " [ 0.43692994]]\n",
      "Round: 11\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007349744216091938\n",
      "2 Fail: due to tiny learning rate( 0.008819693059310326 )\n",
      "Stop, Learning Goal = 0.19977784\n",
      "[[ 0.8783952 ]\n",
      " [-0.3398093 ]\n",
      " [ 0.06741869]\n",
      " [-0.31846416]\n",
      " [-0.8416252 ]\n",
      " [ 0.40627015]\n",
      " [-0.7013023 ]\n",
      " [-0.8309339 ]\n",
      " [ 0.6979595 ]\n",
      " [ 0.23108995]\n",
      " [-0.4134289 ]]\n",
      "Round: 12\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008819693059310326\n",
      "2 Keep learning at learning rate = 0.01058363167117239\n",
      "3 Fail: due to tiny learning rate( 0.007408542169820672 )\n",
      "Stop, Learning Goal = 0.19290371\n",
      "[[-0.8662523 ]\n",
      " [ 0.8852043 ]\n",
      " [-0.3500383 ]\n",
      " [-0.30838525]\n",
      " [ 0.07300158]\n",
      " [ 0.37802356]\n",
      " [-0.6931539 ]\n",
      " [-0.8837321 ]\n",
      " [ 0.7151646 ]\n",
      " [ 0.15356137]\n",
      " [-0.49418616]\n",
      " [-0.38415194]]\n",
      "Round: 13\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007408542169820672\n",
      "2 Fail: due to tiny learning rate( 0.008890250603784806 )\n",
      "Stop, Learning Goal = 0.22009465\n",
      "[[ 0.88409865]\n",
      " [-0.3519324 ]\n",
      " [-0.8555826 ]\n",
      " [-0.3167504 ]\n",
      " [ 0.32383555]\n",
      " [ 0.09622519]\n",
      " [-0.67410755]\n",
      " [-0.9238111 ]\n",
      " [ 0.7336039 ]\n",
      " [ 0.08326755]\n",
      " [-0.567423  ]\n",
      " [-0.28432405]\n",
      " [-0.2199985 ]]\n",
      "Round: 14\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008890250603784806\n",
      "2 Keep learning at learning rate = 0.010668300724541767\n",
      "3 Fail: due to tiny learning rate( 0.007467810507179236 )\n",
      "Stop, Learning Goal = 0.23162286\n",
      "[[ 0.87720037]\n",
      " [ 0.30124113]\n",
      " [-0.8299513 ]\n",
      " [-0.34186694]\n",
      " [ 0.12425509]\n",
      " [-0.3065779 ]\n",
      " [-0.9364619 ]\n",
      " [-0.6493875 ]\n",
      " [ 0.07279876]\n",
      " [ 0.7560122 ]\n",
      " [-0.58484983]\n",
      " [-0.25440285]\n",
      " [-0.3243117 ]\n",
      " [-1.4606745 ]]\n",
      "Round: 15\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007467810507179236\n",
      "2 Fail: due to tiny learning rate( 0.008961372608615082 )\n",
      "Stop, Learning Goal = 0.26191694\n",
      "[[ 0.14756057]\n",
      " [-0.79452384]\n",
      " [ 0.8579353 ]\n",
      " [-0.3460227 ]\n",
      " [ 0.29539248]\n",
      " [-0.31665525]\n",
      " [-0.6211915 ]\n",
      " [-0.9696337 ]\n",
      " [ 0.07049218]\n",
      " [ 0.7541112 ]\n",
      " [-0.61825097]\n",
      " [-0.19483504]\n",
      " [-0.45624337]\n",
      " [-1.3789794 ]\n",
      " [ 0.0756028 ]]\n",
      "Round: 16\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008961372608615082\n",
      "2 Keep learning at learning rate = 0.010753647130338098\n",
      "3 Fail: due to tiny learning rate( 0.007527552991236668 )\n",
      "Stop, Learning Goal = 0.2852962\n",
      "[[ 0.15226603]\n",
      " [-0.34326595]\n",
      " [-0.6229111 ]\n",
      " [-0.998697  ]\n",
      " [ 0.8733757 ]\n",
      " [ 0.28609645]\n",
      " [-0.76233786]\n",
      " [-0.31389147]\n",
      " [ 0.06418449]\n",
      " [ 0.74922067]\n",
      " [-0.62395304]\n",
      " [-0.16008013]\n",
      " [-0.52938884]\n",
      " [-1.3197381 ]\n",
      " [ 0.029822  ]\n",
      " [-0.7458376 ]]\n",
      "Round: 17\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007527552991236668\n",
      "2 Fail: due to tiny learning rate( 0.009033063589484 )\n",
      "Stop, Learning Goal = 0.31439573\n",
      "[[-1.0397278 ]\n",
      " [ 0.93444663]\n",
      " [-0.32718053]\n",
      " [ 0.15647241]\n",
      " [-0.61774504]\n",
      " [-0.309006  ]\n",
      " [ 0.26993093]\n",
      " [-0.749006  ]\n",
      " [ 0.04271229]\n",
      " [ 0.7456926 ]\n",
      " [-0.65865606]\n",
      " [-0.6009962 ]\n",
      " [-0.05104224]\n",
      " [-1.2585506 ]\n",
      " [-0.0247424 ]\n",
      " [-0.5579911 ]\n",
      " [-1.1289724 ]]\n",
      "Round: 18\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009033063589484\n",
      "2 Keep learning at learning rate = 0.0108396763073808\n",
      "3 Fail: due to tiny learning rate( 0.00758777341516656 )\n",
      "Stop, Learning Goal = 0.3283166\n",
      "[[-0.32365555]\n",
      " [ 0.1657266 ]\n",
      " [-0.5936921 ]\n",
      " [-0.3284071 ]\n",
      " [-1.0693804 ]\n",
      " [ 0.98250014]\n",
      " [ 0.25028962]\n",
      " [-0.72746474]\n",
      " [ 0.04481321]\n",
      " [ 0.7550724 ]\n",
      " [-0.68275946]\n",
      " [ 0.01367383]\n",
      " [-0.64930385]\n",
      " [-1.2111081 ]\n",
      " [-0.46801078]\n",
      " [-0.05979682]\n",
      " [-0.9980019 ]\n",
      " [-0.62391824]]\n",
      "Round: 19\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00758777341516656\n",
      "2 Fail: due to tiny learning rate( 0.009105328098199871 )\n",
      "Stop, Learning Goal = 0.34815246\n",
      "[[-0.56398803]\n",
      " [-0.3384626 ]\n",
      " [ 0.15639406]\n",
      " [-0.3250693 ]\n",
      " [-1.1186604 ]\n",
      " [ 0.23991925]\n",
      " [ 1.0651035 ]\n",
      " [-0.68485904]\n",
      " [ 0.00820303]\n",
      " [ 0.76636976]\n",
      " [ 0.08551836]\n",
      " [-0.7357987 ]\n",
      " [-0.72626066]\n",
      " [-1.1760955 ]\n",
      " [-0.36457086]\n",
      " [-0.11683929]\n",
      " [-0.83967626]\n",
      " [-0.38397908]\n",
      " [ 0.22917593]]\n",
      "Round: 20\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009105328098199871\n",
      "2 Keep learning at learning rate = 0.010926393717839844\n",
      "3 Fail: due to tiny learning rate( 0.00764847560248789 )\n",
      "Stop, Learning Goal = 0.3594137\n",
      "[[-0.33935753]\n",
      " [ 0.16376689]\n",
      " [-0.5335849 ]\n",
      " [-0.3247501 ]\n",
      " [-0.01987568]\n",
      " [ 0.23219153]\n",
      " [-1.1272218 ]\n",
      " [-0.65924853]\n",
      " [ 0.7545842 ]\n",
      " [ 1.0840453 ]\n",
      " [ 0.09645923]\n",
      " [-0.7875814 ]\n",
      " [-0.7594697 ]\n",
      " [-0.3067421 ]\n",
      " [-1.1653246 ]\n",
      " [-0.7798123 ]\n",
      " [-0.14431134]\n",
      " [-0.27549866]\n",
      " [ 0.08987113]\n",
      " [ 1.2521678 ]]\n",
      "Round: 21\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00764847560248789\n",
      "2 Fail: due to tiny learning rate( 0.009178170722985468 )\n",
      "Stop, Learning Goal = 0.39685753\n",
      "[[-0.37549305]\n",
      " [ 0.0689742 ]\n",
      " [-0.32170808]\n",
      " [-0.06100392]\n",
      " [-0.5292078 ]\n",
      " [ 0.2074582 ]\n",
      " [-1.1632538 ]\n",
      " [-0.88347363]\n",
      " [ 0.11437345]\n",
      " [ 0.6838621 ]\n",
      " [-0.67600703]\n",
      " [-0.80737126]\n",
      " [ 1.0787256 ]\n",
      " [-0.24095273]\n",
      " [-0.7190324 ]\n",
      " [-1.173878  ]\n",
      " [-0.1713351 ]\n",
      " [-0.21243697]\n",
      " [-0.06679177]\n",
      " [ 1.0964597 ]\n",
      " [ 1.7471113 ]]\n",
      "Round: 22\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009178170722985468\n",
      "2 Keep learning at learning rate = 0.011013804867582562\n",
      "3 Fail: due to tiny learning rate( 0.007709663407307793 )\n",
      "Stop, Learning Goal = 0.41581059\n",
      "[[-0.07038694]\n",
      " [-0.9174648 ]\n",
      " [-0.40188438]\n",
      " [-0.317748  ]\n",
      " [ 0.01065738]\n",
      " [-0.5287162 ]\n",
      " [ 0.1967333 ]\n",
      " [-0.83835775]\n",
      " [ 0.12577313]\n",
      " [-1.1721156 ]\n",
      " [-0.70599395]\n",
      " [ 1.0944147 ]\n",
      " [ 0.66297215]\n",
      " [-0.20448023]\n",
      " [-0.6752458 ]\n",
      " [-0.08758824]\n",
      " [-1.1828576 ]\n",
      " [-0.24310511]\n",
      " [-0.16658133]\n",
      " [ 1.0264721 ]\n",
      " [ 1.623311  ]\n",
      " [-1.0469182 ]]\n",
      "Round: 23\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007709663407307793\n",
      "2 Fail: due to tiny learning rate( 0.00925159608876935 )\n",
      "Stop, Learning Goal = 0.44561756\n",
      "[[-9.6008658e-01]\n",
      " [-8.6104169e-02]\n",
      " [-3.0327916e-01]\n",
      " [-5.1891345e-01]\n",
      " [-4.6141028e-01]\n",
      " [-9.0584517e-01]\n",
      " [-6.5063611e-02]\n",
      " [ 2.1425669e-01]\n",
      " [-7.5447214e-01]\n",
      " [ 1.3814281e-01]\n",
      " [-1.1633949e+00]\n",
      " [ 1.1196795e+00]\n",
      " [ 6.0584527e-01]\n",
      " [-1.6059543e-01]\n",
      " [-6.0796261e-01]\n",
      " [-5.9153140e-04]\n",
      " [-3.0976582e-01]\n",
      " [-3.1730437e-01]\n",
      " [-1.2213665e+00]\n",
      " [ 9.2262650e-01]\n",
      " [ 1.4331839e+00]\n",
      " [-9.3306792e-01]\n",
      " [ 8.9073443e-01]]\n",
      "Round: 24\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00925159608876935\n",
      "2 Keep learning at learning rate = 0.01110191530652322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Fail: due to tiny learning rate( 0.007771340714566254 )\n",
      "Stop, Learning Goal = 0.4575669\n",
      "[[-0.11906206]\n",
      " [-0.28441095]\n",
      " [-0.97793496]\n",
      " [-0.9596137 ]\n",
      " [-0.5061438 ]\n",
      " [-0.81716955]\n",
      " [ 0.20825613]\n",
      " [ 0.14856637]\n",
      " [-0.47816575]\n",
      " [-1.133519  ]\n",
      " [-0.10346686]\n",
      " [ 1.1012701 ]\n",
      " [ 0.5853129 ]\n",
      " [-0.16154039]\n",
      " [-0.00452041]\n",
      " [-0.5665499 ]\n",
      " [-0.4157133 ]\n",
      " [-0.3521042 ]\n",
      " [-1.2650764 ]\n",
      " [ 0.83791256]\n",
      " [ 1.3038968 ]\n",
      " [ 0.75980794]\n",
      " [-0.8755313 ]\n",
      " [ 1.3481231 ]]\n",
      "Round: 25\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007771340714566254\n",
      "2 Fail: due to tiny learning rate( 0.009325608857479505 )\n",
      "Stop, Learning Goal = 0.4717592\n",
      "[[-1.0165979 ]\n",
      " [-0.239483  ]\n",
      " [-0.8529085 ]\n",
      " [-0.15616024]\n",
      " [-0.99522054]\n",
      " [-0.43616927]\n",
      " [ 0.15632021]\n",
      " [ 0.23097783]\n",
      " [-1.0743233 ]\n",
      " [-0.4651469 ]\n",
      " [ 1.0990661 ]\n",
      " [-0.09463084]\n",
      " [-0.13885796]\n",
      " [-0.53041494]\n",
      " [ 0.58320165]\n",
      " [-0.48879743]\n",
      " [ 0.00913811]\n",
      " [-0.38998628]\n",
      " [-1.2943882 ]\n",
      " [ 0.71860695]\n",
      " [ 1.1693028 ]\n",
      " [ 0.6077198 ]\n",
      " [ 0.99687415]\n",
      " [-0.82293123]\n",
      " [-1.2434202 ]]\n",
      "Round: 26\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009325608857479505\n",
      "2 Keep learning at learning rate = 0.011190730628975406\n",
      "3 Fail: due to tiny learning rate( 0.007833511440282784 )\n",
      "Stop, Learning Goal = 0.4810438\n",
      "[[-0.865544  ]\n",
      " [-0.18711597]\n",
      " [-1.0462757 ]\n",
      " [-0.9791505 ]\n",
      " [-1.0275408 ]\n",
      " [-0.17215985]\n",
      " [ 0.24519378]\n",
      " [ 0.16973525]\n",
      " [-0.44104904]\n",
      " [-0.36961812]\n",
      " [ 1.0933349 ]\n",
      " [-0.5928027 ]\n",
      " [-0.08782936]\n",
      " [-0.4266978 ]\n",
      " [-0.1289733 ]\n",
      " [ 0.6009847 ]\n",
      " [ 0.05068224]\n",
      " [-0.38908887]\n",
      " [-1.2766148 ]\n",
      " [ 0.67540985]\n",
      " [ 1.116492  ]\n",
      " [ 0.83114094]\n",
      " [ 0.5318909 ]\n",
      " [-0.77714425]\n",
      " [-1.1580832 ]\n",
      " [-2.4749908 ]]\n",
      "Round: 27\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007833511440282784\n",
      "2 Fail: due to tiny learning rate( 0.00940021372833934 )\n",
      "Stop, Learning Goal = 0.50611764\n",
      "[[-0.926999  ]\n",
      " [-0.9632586 ]\n",
      " [-0.94109666]\n",
      " [-0.12867008]\n",
      " [ 0.27543122]\n",
      " [ 0.16612543]\n",
      " [-0.1895567 ]\n",
      " [-1.1007835 ]\n",
      " [-0.38975322]\n",
      " [-0.6536268 ]\n",
      " [ 1.0672992 ]\n",
      " [-0.349455  ]\n",
      " [-0.07794361]\n",
      " [-0.29664683]\n",
      " [-0.12999783]\n",
      " [ 0.636238  ]\n",
      " [ 0.07241513]\n",
      " [-0.38023412]\n",
      " [-1.2717458 ]\n",
      " [ 0.6282871 ]\n",
      " [ 1.0558819 ]\n",
      " [ 0.6157119 ]\n",
      " [ 0.428599  ]\n",
      " [-0.7039583 ]\n",
      " [-1.0514334 ]\n",
      " [-2.309052  ]\n",
      " [ 2.57436   ]]\n",
      "Round: 28\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00940021372833934\n",
      "2 Keep learning at learning rate = 0.011280256474007207\n",
      "3 Fail: due to tiny learning rate( 0.007896179531805044 )\n",
      "Stop, Learning Goal = 0.5333455\n",
      "[[-0.9019637 ]\n",
      " [-0.940415  ]\n",
      " [ 0.34711954]\n",
      " [-0.36824396]\n",
      " [-0.971437  ]\n",
      " [ 0.16517112]\n",
      " [-0.66162944]\n",
      " [-0.19543627]\n",
      " [-0.09472433]\n",
      " [-0.29913738]\n",
      " [-1.1085877 ]\n",
      " [ 1.0575972 ]\n",
      " [-0.0917168 ]\n",
      " [ 0.63217366]\n",
      " [-0.2546846 ]\n",
      " [-0.10705617]\n",
      " [ 0.07849571]\n",
      " [-0.37475136]\n",
      " [ 0.5294552 ]\n",
      " [-1.2488519 ]\n",
      " [ 0.5993297 ]\n",
      " [ 1.0081208 ]\n",
      " [ 0.3685741 ]\n",
      " [-0.6860466 ]\n",
      " [-0.9993361 ]\n",
      " [-2.2035508 ]\n",
      " [ 2.4874015 ]\n",
      " [-3.0418787 ]]\n",
      "Round: 29\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007896179531805044\n",
      "2 Fail: due to tiny learning rate( 0.009475415438166053 )\n",
      "Stop, Learning Goal = 0.57692647\n",
      "[[ 0.46989006]\n",
      " [-0.8543787 ]\n",
      " [-0.2998259 ]\n",
      " [-0.90125084]\n",
      " [-0.20845723]\n",
      " [-0.6089845 ]\n",
      " [ 0.15933275]\n",
      " [-0.21559477]\n",
      " [-1.0135231 ]\n",
      " [-1.1086038 ]\n",
      " [ 1.0400152 ]\n",
      " [-0.05190145]\n",
      " [-0.06260478]\n",
      " [-0.05358493]\n",
      " [ 0.64019936]\n",
      " [ 0.08630574]\n",
      " [-0.17838669]\n",
      " [-0.32673854]\n",
      " [ 0.4538597 ]\n",
      " [-1.1788903 ]\n",
      " [ 0.5586858 ]\n",
      " [ 0.9939045 ]\n",
      " [ 0.3215158 ]\n",
      " [-0.7034389 ]\n",
      " [-0.90080786]\n",
      " [-2.055324  ]\n",
      " [ 2.3773327 ]\n",
      " [-2.7495947 ]\n",
      " [-1.5985509 ]]\n",
      "Round: 30\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009475415438166053\n",
      "2 Keep learning at learning rate = 0.011370498525799263\n",
      "3 Fail: due to tiny learning rate( 0.007959348968059483 )\n",
      "Stop, Learning Goal = 0.6259679\n",
      "[[-0.14429046]\n",
      " [-0.26456928]\n",
      " [-0.81446576]\n",
      " [-0.9082415 ]\n",
      " [ 0.17075418]\n",
      " [ 0.5260991 ]\n",
      " [-0.23970367]\n",
      " [-0.5714412 ]\n",
      " [ 1.045289  ]\n",
      " [-1.094282  ]\n",
      " [-1.0465604 ]\n",
      " [-0.05103274]\n",
      " [-0.02391066]\n",
      " [-0.01175441]\n",
      " [ 0.68711305]\n",
      " [ 0.08906113]\n",
      " [-0.16780187]\n",
      " [ 0.4334079 ]\n",
      " [-0.26522082]\n",
      " [-1.1043717 ]\n",
      " [ 0.6003016 ]\n",
      " [ 1.004393  ]\n",
      " [ 0.33657932]\n",
      " [-0.85510993]\n",
      " [-0.68702793]\n",
      " [-1.9637308 ]\n",
      " [ 2.3017209 ]\n",
      " [-2.5824976 ]\n",
      " [-1.497894  ]\n",
      " [-2.1698935 ]]\n",
      "Round: 31\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007959348968059483\n",
      "2 Fail: due to tiny learning rate( 0.009551218761671379 )\n",
      "Stop, Learning Goal = 0.6812499\n",
      "[[-0.01995882]\n",
      " [-0.20962319]\n",
      " [-0.9037005 ]\n",
      " [ 0.19963875]\n",
      " [-0.7109815 ]\n",
      " [-1.1343001 ]\n",
      " [ 1.0122961 ]\n",
      " [-0.29032096]\n",
      " [ 0.06381264]\n",
      " [-0.02432755]\n",
      " [-0.4965565 ]\n",
      " [ 0.6128576 ]\n",
      " [-1.1067265 ]\n",
      " [ 0.777125  ]\n",
      " [ 0.07169142]\n",
      " [ 0.08444229]\n",
      " [ 0.40488723]\n",
      " [-0.1452224 ]\n",
      " [-0.9939233 ]\n",
      " [-0.17751053]\n",
      " [ 0.6854098 ]\n",
      " [ 1.0173322 ]\n",
      " [ 0.34295192]\n",
      " [-0.77090454]\n",
      " [-1.8157476 ]\n",
      " [-0.6487098 ]\n",
      " [ 2.1710305 ]\n",
      " [-2.3693624 ]\n",
      " [-1.3467146 ]\n",
      " [-1.9318844 ]\n",
      " [-2.0413547 ]]\n",
      "Round: 32\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009551218761671379\n",
      "2 Keep learning at learning rate = 0.011461462514005654\n",
      "3 Fail: due to tiny learning rate( 0.008023023759803958 )\n",
      "Stop, Learning Goal = 0.72549284\n",
      "[[ 0.21521665]\n",
      " [-0.9000459 ]\n",
      " [ 0.15936615]\n",
      " [-0.18858503]\n",
      " [ 1.0138047 ]\n",
      " [ 0.81250846]\n",
      " [-0.03074758]\n",
      " [ 0.07098533]\n",
      " [-1.1594942 ]\n",
      " [-0.6504023 ]\n",
      " [-0.33755326]\n",
      " [-0.45554364]\n",
      " [-1.1389325 ]\n",
      " [ 0.65381163]\n",
      " [ 0.09087552]\n",
      " [ 0.10835744]\n",
      " [ 0.38506025]\n",
      " [-0.9420121 ]\n",
      " [-0.15748356]\n",
      " [-0.10527329]\n",
      " [ 1.0174063 ]\n",
      " [ 0.7287922 ]\n",
      " [ 0.33920097]\n",
      " [-0.7051105 ]\n",
      " [-1.7534282 ]\n",
      " [-0.6404573 ]\n",
      " [ 2.1244817 ]\n",
      " [-2.2257206 ]\n",
      " [-1.2504587 ]\n",
      " [-1.8196718 ]\n",
      " [-1.8061085 ]\n",
      " [-2.7068272 ]]\n",
      "Round: 33\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008023023759803958\n",
      "2 Fail: due to tiny learning rate( 0.00962762851176475 )\n",
      "Stop, Learning Goal = 0.7760536\n",
      "[[ 0.28918165]\n",
      " [ 0.22078627]\n",
      " [-0.9059593 ]\n",
      " [ 0.8463361 ]\n",
      " [ 0.97647184]\n",
      " [-0.13012224]\n",
      " [-0.0384112 ]\n",
      " [-1.1547117 ]\n",
      " [-0.40653712]\n",
      " [-0.5934177 ]\n",
      " [ 0.17735451]\n",
      " [-1.15945   ]\n",
      " [-0.38524646]\n",
      " [ 0.03253084]\n",
      " [ 0.71238744]\n",
      " [-0.8627319 ]\n",
      " [ 0.33912855]\n",
      " [ 0.15462404]\n",
      " [-0.19762307]\n",
      " [-0.02365416]\n",
      " [ 1.0106399 ]\n",
      " [ 0.7708152 ]\n",
      " [ 0.34165138]\n",
      " [-0.62172914]\n",
      " [-1.6817286 ]\n",
      " [-0.68376   ]\n",
      " [-2.0003915 ]\n",
      " [ 2.0409358 ]\n",
      " [-1.1020412 ]\n",
      " [-1.5316346 ]\n",
      " [-1.6298056 ]\n",
      " [-2.510723  ]\n",
      " [ 1.957603  ]]\n",
      "Round: 34\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00962762851176475\n",
      "2 Keep learning at learning rate = 0.011553154214117699\n",
      "3 Fail: due to tiny learning rate( 0.008087207949882389 )\n",
      "Stop, Learning Goal = 0.8251659\n",
      "[[ 0.2433229 ]\n",
      " [ 0.8454774 ]\n",
      " [ 0.983815  ]\n",
      " [-0.89324087]\n",
      " [ 0.36821395]\n",
      " [-0.05643351]\n",
      " [-0.1193635 ]\n",
      " [-1.1781287 ]\n",
      " [-0.87139636]\n",
      " [-1.1882769 ]\n",
      " [ 0.29318136]\n",
      " [-0.55348414]\n",
      " [-0.4441175 ]\n",
      " [ 0.00990956]\n",
      " [-0.3484034 ]\n",
      " [ 0.753716  ]\n",
      " [ 0.25587183]\n",
      " [-0.21908052]\n",
      " [ 0.17125766]\n",
      " [ 0.9825889 ]\n",
      " [ 0.00513707]\n",
      " [ 0.8028179 ]\n",
      " [ 0.3062995 ]\n",
      " [-0.56639695]\n",
      " [-1.661645  ]\n",
      " [-1.8788435 ]\n",
      " [ 2.0046327 ]\n",
      " [-0.6857086 ]\n",
      " [-1.0198169 ]\n",
      " [-1.3585135 ]\n",
      " [-1.5618169 ]\n",
      " [-2.3634293 ]\n",
      " [ 1.8623977 ]\n",
      " [-2.627498  ]]\n",
      "Round: 35\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008087207949882389\n",
      "2 Fail: due to tiny learning rate( 0.009704649539858867 )\n",
      "Stop, Learning Goal = 0.88323736\n",
      "[[ 0.24469498]\n",
      " [ 0.8090707 ]\n",
      " [ 1.008738  ]\n",
      " [-0.85559285]\n",
      " [-0.08259657]\n",
      " [ 0.4515784 ]\n",
      " [-0.14818665]\n",
      " [-1.2172799 ]\n",
      " [ 0.2333574 ]\n",
      " [-0.90602803]\n",
      " [-1.2307839 ]\n",
      " [-0.4624996 ]\n",
      " [-0.5548208 ]\n",
      " [-0.23157343]\n",
      " [ 0.02470079]\n",
      " [-0.32748458]\n",
      " [ 0.7962371 ]\n",
      " [ 0.13804498]\n",
      " [ 0.35104778]\n",
      " [ 0.9040426 ]\n",
      " [-0.01277801]\n",
      " [-0.5164062 ]\n",
      " [ 0.19605663]\n",
      " [-1.7560582 ]\n",
      " [ 0.8210696 ]\n",
      " [-1.6644403 ]\n",
      " [ 1.9654896 ]\n",
      " [-0.64720726]\n",
      " [-1.1744822 ]\n",
      " [-0.95055175]\n",
      " [-1.5234632 ]\n",
      " [-2.1875997 ]\n",
      " [ 1.7818923 ]\n",
      " [-2.4095042 ]\n",
      " [ 2.325343  ]]\n",
      "Round: 36\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009704649539858867\n",
      "2 Keep learning at learning rate = 0.01164557944783064\n",
      "3 Fail: due to tiny learning rate( 0.008151905613481447 )\n",
      "Stop, Learning Goal = 0.9238065\n",
      "[[ 0.23270455]\n",
      " [ 1.0524005 ]\n",
      " [ 0.7859622 ]\n",
      " [-0.8394711 ]\n",
      " [-0.17094454]\n",
      " [-0.09886464]\n",
      " [ 0.216342  ]\n",
      " [-1.2366841 ]\n",
      " [ 0.52488995]\n",
      " [-0.91376936]\n",
      " [-0.2532284 ]\n",
      " [-0.5924884 ]\n",
      " [ 0.0474706 ]\n",
      " [-0.47581634]\n",
      " [-1.2629374 ]\n",
      " [ 0.12867251]\n",
      " [-0.32057294]\n",
      " [ 0.8285006 ]\n",
      " [ 0.42137662]\n",
      " [ 0.8485379 ]\n",
      " [ 0.11942545]\n",
      " [-1.690288  ]\n",
      " [-0.4819722 ]\n",
      " [-0.00241086]\n",
      " [-1.6652027 ]\n",
      " [ 0.8269174 ]\n",
      " [ 1.938714  ]\n",
      " [-0.5904069 ]\n",
      " [-1.0639422 ]\n",
      " [-0.9035276 ]\n",
      " [-1.4780635 ]\n",
      " [-2.071397  ]\n",
      " [ 1.7549869 ]\n",
      " [-2.2603595 ]\n",
      " [ 2.2219658 ]\n",
      " [-2.1617723 ]]\n",
      "Round: 37\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008151905613481447\n",
      "2 Fail: due to tiny learning rate( 0.009782286736177736 )\n",
      "Stop, Learning Goal = 0.97147864\n",
      "[[ 0.22078332]\n",
      " [ 0.78015244]\n",
      " [-0.14145938]\n",
      " [-0.77615535]\n",
      " [ 1.0593597 ]\n",
      " [ 0.16515478]\n",
      " [-0.07464871]\n",
      " [-1.2170576 ]\n",
      " [-0.8950838 ]\n",
      " [-0.6664647 ]\n",
      " [-0.24113455]\n",
      " [ 0.05073521]\n",
      " [ 0.6120721 ]\n",
      " [ 0.16788921]\n",
      " [-0.483874  ]\n",
      " [-1.2323962 ]\n",
      " [-0.29262045]\n",
      " [ 0.8953408 ]\n",
      " [ 0.7909976 ]\n",
      " [ 0.50443447]\n",
      " [ 0.04711041]\n",
      " [-1.589589  ]\n",
      " [-0.39373812]\n",
      " [-0.00504223]\n",
      " [-1.6352504 ]\n",
      " [ 0.83136094]\n",
      " [ 1.9324363 ]\n",
      " [-0.5469936 ]\n",
      " [-0.9151058 ]\n",
      " [-0.8168043 ]\n",
      " [-1.4147742 ]\n",
      " [-1.9449104 ]\n",
      " [ 1.6583918 ]\n",
      " [-2.0896552 ]\n",
      " [-1.9085542 ]\n",
      " [ 2.1155663 ]\n",
      " [-3.964068  ]]\n",
      "Round: 38\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009782286736177736\n",
      "2 Keep learning at learning rate = 0.011738744083413284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Fail: due to tiny learning rate( 0.008217120858389299 )\n",
      "Stop, Learning Goal = 1.0083549\n",
      "[[ 0.21541019]\n",
      " [ 0.7972631 ]\n",
      " [ 0.06563582]\n",
      " [ 1.0477874 ]\n",
      " [-0.08572607]\n",
      " [ 0.00942887]\n",
      " [-0.7227439 ]\n",
      " [-0.7404502 ]\n",
      " [-1.1774366 ]\n",
      " [-0.8791161 ]\n",
      " [ 0.03150292]\n",
      " [-0.2130243 ]\n",
      " [-1.1700299 ]\n",
      " [-0.48742324]\n",
      " [ 0.19472022]\n",
      " [ 0.6728905 ]\n",
      " [-0.2420253 ]\n",
      " [ 0.7702817 ]\n",
      " [ 1.0268257 ]\n",
      " [ 0.00811644]\n",
      " [-1.5006732 ]\n",
      " [-0.3132046 ]\n",
      " [ 0.55972284]\n",
      " [-0.01688103]\n",
      " [-1.6209009 ]\n",
      " [ 0.8316302 ]\n",
      " [-0.5407116 ]\n",
      " [ 1.933492  ]\n",
      " [-0.8134474 ]\n",
      " [-0.7294967 ]\n",
      " [-1.3711565 ]\n",
      " [-1.8774328 ]\n",
      " [ 1.5602374 ]\n",
      " [-1.9900515 ]\n",
      " [-1.763226  ]\n",
      " [ 2.0614595 ]\n",
      " [-3.833334  ]\n",
      " [-3.0461888 ]]\n",
      "Round: 39\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008217120858389299\n",
      "2 Fail: due to tiny learning rate( 0.009860545030067157 )\n",
      "Stop, Learning Goal = 1.0436337\n",
      "[[ 0.20542169]\n",
      " [-0.05189797]\n",
      " [ 0.10433745]\n",
      " [ 0.85464275]\n",
      " [ 1.0865355 ]\n",
      " [-0.8299298 ]\n",
      " [-1.1210603 ]\n",
      " [-0.04156804]\n",
      " [-0.6529355 ]\n",
      " [-0.85814416]\n",
      " [-1.0884063 ]\n",
      " [ 0.0545243 ]\n",
      " [-0.17018425]\n",
      " [-0.5088179 ]\n",
      " [ 0.20450401]\n",
      " [ 0.7590327 ]\n",
      " [ 0.75803614]\n",
      " [-1.3770027 ]\n",
      " [-0.23121488]\n",
      " [-0.06775308]\n",
      " [-0.21596384]\n",
      " [ 1.1933503 ]\n",
      " [ 0.6468897 ]\n",
      " [-0.02981275]\n",
      " [-1.5690303 ]\n",
      " [ 0.851971  ]\n",
      " [-0.46520746]\n",
      " [ 1.9347544 ]\n",
      " [-0.66501474]\n",
      " [-0.67366254]\n",
      " [-1.297694  ]\n",
      " [-1.7808375 ]\n",
      " [ 1.455242  ]\n",
      " [-1.837244  ]\n",
      " [-1.5516555 ]\n",
      " [ 1.952836  ]\n",
      " [-3.666479  ]\n",
      " [-2.668302  ]\n",
      " [-2.8617668 ]]\n",
      "Round: 40\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009860545030067157\n",
      "2 Keep learning at learning rate = 0.011832654036080588\n",
      "3 Fail: due to tiny learning rate( 0.008282857825256411 )\n",
      "Stop, Learning Goal = 1.0563744\n",
      "[[ 0.15741566]\n",
      " [ 0.1867111 ]\n",
      " [-0.13894323]\n",
      " [ 0.90380096]\n",
      " [-0.8729031 ]\n",
      " [-1.096528  ]\n",
      " [ 1.1163545 ]\n",
      " [-1.031225  ]\n",
      " [-0.8485079 ]\n",
      " [-0.03649971]\n",
      " [ 0.07693103]\n",
      " [-0.6107911 ]\n",
      " [-1.3007569 ]\n",
      " [-0.13726434]\n",
      " [-0.5298543 ]\n",
      " [ 0.74743235]\n",
      " [-0.1078026 ]\n",
      " [ 0.2058684 ]\n",
      " [-0.1418468 ]\n",
      " [-0.23439261]\n",
      " [ 0.792776  ]\n",
      " [-0.03547081]\n",
      " [-1.5452745 ]\n",
      " [ 0.6803262 ]\n",
      " [ 1.2938884 ]\n",
      " [ 0.8557308 ]\n",
      " [-0.40169153]\n",
      " [-0.5581292 ]\n",
      " [ 1.9320514 ]\n",
      " [-0.6603308 ]\n",
      " [-1.2477534 ]\n",
      " [-1.7099164 ]\n",
      " [ 1.4157236 ]\n",
      " [-1.7257891 ]\n",
      " [-1.406706  ]\n",
      " [ 1.8808068 ]\n",
      " [-2.448151  ]\n",
      " [-3.5708272 ]\n",
      " [-2.664692  ]\n",
      " [-2.4031339 ]]\n",
      "Round: 41\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008282857825256411\n",
      "2 Fail: due to tiny learning rate( 0.009939429390307694 )\n",
      "Stop, Learning Goal = 1.0820609\n",
      "[[ 0.21321532]\n",
      " [ 0.9587116 ]\n",
      " [-0.9548874 ]\n",
      " [ 0.13879296]\n",
      " [-1.0601964 ]\n",
      " [-0.28753844]\n",
      " [-0.9724021 ]\n",
      " [ 1.1259611 ]\n",
      " [-0.8502264 ]\n",
      " [-0.02526215]\n",
      " [-1.1918118 ]\n",
      " [ 0.07814321]\n",
      " [-0.5997088 ]\n",
      " [-0.01604262]\n",
      " [-0.14857772]\n",
      " [ 0.6821493 ]\n",
      " [-0.5868585 ]\n",
      " [-0.11032048]\n",
      " [ 0.17230734]\n",
      " [-0.19741026]\n",
      " [ 0.81437933]\n",
      " [-0.06661287]\n",
      " [-1.5711123 ]\n",
      " [ 0.70290947]\n",
      " [-0.41874388]\n",
      " [-0.3559474 ]\n",
      " [ 0.8327627 ]\n",
      " [ 1.4189081 ]\n",
      " [ 1.9075805 ]\n",
      " [-0.6168699 ]\n",
      " [-1.1854669 ]\n",
      " [-1.6205791 ]\n",
      " [ 1.3232086 ]\n",
      " [-1.5802159 ]\n",
      " [-1.2140269 ]\n",
      " [-2.1267292 ]\n",
      " [ 1.7675904 ]\n",
      " [-3.4261878 ]\n",
      " [-2.4201372 ]\n",
      " [-2.0544686 ]\n",
      " [ 3.843699  ]]\n",
      "Round: 42\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009939429390307694\n",
      "2 Keep learning at learning rate = 0.011927315268369232\n",
      "3 Fail: due to tiny learning rate( 0.008349120687858463 )\n",
      "Stop, Learning Goal = 1.0888845\n",
      "[[ 1.0021806 ]\n",
      " [-1.0167941 ]\n",
      " [ 0.26362884]\n",
      " [-1.0346707 ]\n",
      " [ 0.12539038]\n",
      " [-0.9201299 ]\n",
      " [-1.1406268 ]\n",
      " [ 1.1232425 ]\n",
      " [-0.8569064 ]\n",
      " [ 0.07817015]\n",
      " [-0.38918194]\n",
      " [-0.01164761]\n",
      " [ 0.07957992]\n",
      " [ 0.64239657]\n",
      " [-0.17096701]\n",
      " [-0.6059158 ]\n",
      " [ 0.15101084]\n",
      " [-0.08308354]\n",
      " [-0.64396346]\n",
      " [-0.18176201]\n",
      " [ 0.8054756 ]\n",
      " [-0.11487868]\n",
      " [-0.33949175]\n",
      " [-1.5818971 ]\n",
      " [-0.34334293]\n",
      " [ 0.72161317]\n",
      " [ 0.8162794 ]\n",
      " [ 1.8961146 ]\n",
      " [ 1.4851803 ]\n",
      " [-0.5914147 ]\n",
      " [-1.1444428 ]\n",
      " [-1.6016912 ]\n",
      " [-1.1235691 ]\n",
      " [ 1.245751  ]\n",
      " [-1.5153738 ]\n",
      " [-1.9030279 ]\n",
      " [ 1.7011917 ]\n",
      " [-3.2968578 ]\n",
      " [-2.272075  ]\n",
      " [-1.8421334 ]\n",
      " [ 3.6375506 ]\n",
      " [ 3.0533593 ]]\n",
      "Round: 43\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008349120687858463\n",
      "2 Keep learning at learning rate = 0.010018944825430155\n",
      "3 Fail: due to tiny learning rate( 0.007013261377801108 )\n",
      "Stop, Learning Goal = 1.1123232\n",
      "[[ 1.0579416 ]\n",
      " [-0.88096166]\n",
      " [-1.020224  ]\n",
      " [-1.0575407 ]\n",
      " [ 0.32841218]\n",
      " [ 0.09336519]\n",
      " [-1.106787  ]\n",
      " [ 0.16273761]\n",
      " [ 1.0977757 ]\n",
      " [-0.87113976]\n",
      " [ 0.01005554]\n",
      " [ 0.05736184]\n",
      " [ 0.621928  ]\n",
      " [-0.20530891]\n",
      " [-0.5816865 ]\n",
      " [-0.5064629 ]\n",
      " [ 0.13463211]\n",
      " [-0.03629768]\n",
      " [-0.6992781 ]\n",
      " [-0.19814658]\n",
      " [ 0.7388098 ]\n",
      " [-0.2535169 ]\n",
      " [-0.17565286]\n",
      " [-1.5678703 ]\n",
      " [-0.32448483]\n",
      " [ 0.79842657]\n",
      " [ 0.7160852 ]\n",
      " [ 1.8599184 ]\n",
      " [ 1.5702205 ]\n",
      " [-0.57279116]\n",
      " [-1.1205772 ]\n",
      " [-1.6162096 ]\n",
      " [-1.0594747 ]\n",
      " [ 1.1601822 ]\n",
      " [-1.4612854 ]\n",
      " [-1.6953571 ]\n",
      " [ 1.6260269 ]\n",
      " [-1.6456578 ]\n",
      " [-3.1637251 ]\n",
      " [-2.128195  ]\n",
      " [ 3.4498668 ]\n",
      " [ 2.9008114 ]\n",
      " [ 3.7000008 ]]\n",
      "Round: 44\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007013261377801108\n",
      "2 Fail: due to tiny learning rate( 0.00841591365336133 )\n",
      "Stop, Learning Goal = 1.136593\n",
      "[[-0.8211726 ]\n",
      " [-1.0026821 ]\n",
      " [ 0.3092415 ]\n",
      " [-1.0600674 ]\n",
      " [ 1.1036756 ]\n",
      " [-1.1149682 ]\n",
      " [ 0.10709509]\n",
      " [ 0.41089496]\n",
      " [ 1.092467  ]\n",
      " [-0.906868  ]\n",
      " [ 0.5806785 ]\n",
      " [-0.2591814 ]\n",
      " [ 0.04229459]\n",
      " [ 0.06799242]\n",
      " [ 0.12789592]\n",
      " [-0.56893873]\n",
      " [-0.6576623 ]\n",
      " [ 0.02454361]\n",
      " [-0.21129504]\n",
      " [ 0.688869  ]\n",
      " [-0.15888181]\n",
      " [-0.73978484]\n",
      " [-0.25511578]\n",
      " [-1.5546924 ]\n",
      " [-0.29126778]\n",
      " [ 0.7641301 ]\n",
      " [ 0.7588514 ]\n",
      " [ 1.8373154 ]\n",
      " [ 1.635681  ]\n",
      " [-0.5361657 ]\n",
      " [-1.1051086 ]\n",
      " [-1.6029166 ]\n",
      " [-0.9308349 ]\n",
      " [ 1.0655347 ]\n",
      " [-1.4246743 ]\n",
      " [-1.350946  ]\n",
      " [-1.4032351 ]\n",
      " [ 1.5115286 ]\n",
      " [-2.9777327 ]\n",
      " [-1.9558967 ]\n",
      " [ 3.1897054 ]\n",
      " [ 2.6936576 ]\n",
      " [ 3.4778013 ]\n",
      " [-3.9243312 ]]\n",
      "Round: 45\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00841591365336133\n",
      "2 Keep learning at learning rate = 0.010099096384033595\n",
      "3 Fail: due to tiny learning rate( 0.007069367468823516 )\n",
      "Stop, Learning Goal = 1.1609333\n",
      "[[-8.0149722e-01]\n",
      " [ 3.5335460e-01]\n",
      " [-1.0136548e+00]\n",
      " [-1.0554990e+00]\n",
      " [ 1.0724762e-01]\n",
      " [ 1.1220171e+00]\n",
      " [-1.1423020e+00]\n",
      " [ 1.0896368e+00]\n",
      " [ 4.3216661e-01]\n",
      " [-3.0639526e-01]\n",
      " [ 5.3140855e-01]\n",
      " [-9.3950164e-01]\n",
      " [ 1.0671309e-01]\n",
      " [ 3.3471882e-03]\n",
      " [ 1.0824183e-01]\n",
      " [-5.9516931e-01]\n",
      " [-1.1119482e-01]\n",
      " [ 6.4026332e-01]\n",
      " [-2.3415121e-01]\n",
      " [-3.2015869e-01]\n",
      " [ 2.9583365e-02]\n",
      " [-7.5216722e-01]\n",
      " [-7.2832906e-01]\n",
      " [-1.5666720e+00]\n",
      " [-2.3008427e-01]\n",
      " [ 7.5101125e-01]\n",
      " [ 7.5898004e-01]\n",
      " [ 1.8281794e+00]\n",
      " [-5.5623162e-01]\n",
      " [ 1.6526626e+00]\n",
      " [-1.0966215e+00]\n",
      " [-1.6057565e+00]\n",
      " [-1.2876629e+00]\n",
      " [-8.6276853e-01]\n",
      " [ 1.0322760e+00]\n",
      " [-1.2856574e+00]\n",
      " [-1.2344307e+00]\n",
      " [ 1.4084431e+00]\n",
      " [-2.8835163e+00]\n",
      " [-1.8253880e+00]\n",
      " [ 3.0344238e+00]\n",
      " [ 2.5676956e+00]\n",
      " [ 3.3347228e+00]\n",
      " [-3.8290975e+00]\n",
      " [ 4.3482633e+00]]\n",
      "Round: 46\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007069367468823516\n",
      "2 Fail: due to tiny learning rate( 0.008483240962588219 )\n",
      "Stop, Learning Goal = 1.1990551\n",
      "[[-0.73319536]\n",
      " [-0.9788361 ]\n",
      " [-1.0458162 ]\n",
      " [ 0.39496684]\n",
      " [ 0.14530462]\n",
      " [ 1.1812022 ]\n",
      " [ 1.093842  ]\n",
      " [-1.1517911 ]\n",
      " [ 0.5099467 ]\n",
      " [-0.3327394 ]\n",
      " [ 0.14036292]\n",
      " [ 0.48566076]\n",
      " [-0.05138642]\n",
      " [-0.9559091 ]\n",
      " [ 0.09794444]\n",
      " [-0.6280132 ]\n",
      " [-0.03737491]\n",
      " [ 0.57957894]\n",
      " [-0.40294367]\n",
      " [-0.24287301]\n",
      " [ 0.02303678]\n",
      " [-0.7488659 ]\n",
      " [-0.7749079 ]\n",
      " [-0.13856047]\n",
      " [-1.5514729 ]\n",
      " [ 0.77910894]\n",
      " [ 0.73537606]\n",
      " [ 1.8154073 ]\n",
      " [-0.5879975 ]\n",
      " [ 1.6639645 ]\n",
      " [-1.0089021 ]\n",
      " [-1.0857933 ]\n",
      " [-1.6513169 ]\n",
      " [-0.78624755]\n",
      " [ 0.96569175]\n",
      " [-1.2304688 ]\n",
      " [-0.99279207]\n",
      " [ 1.3059738 ]\n",
      " [-2.7202327 ]\n",
      " [-1.6263597 ]\n",
      " [ 2.8508162 ]\n",
      " [ 2.3628845 ]\n",
      " [ 3.1435707 ]\n",
      " [-3.7065358 ]\n",
      " [ 3.9768887 ]\n",
      " [-4.0499663 ]]\n",
      "Round: 47\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008483240962588219\n",
      "2 Keep learning at learning rate = 0.010179889155105861\n",
      "3 Fail: due to tiny learning rate( 0.007125922408574102 )\n",
      "Stop, Learning Goal = 1.2173985\n",
      "[[-9.4030261e-01]\n",
      " [-1.0571151e+00]\n",
      " [-6.7382801e-01]\n",
      " [ 1.3621366e-01]\n",
      " [ 4.2391050e-01]\n",
      " [-3.3752525e-01]\n",
      " [ 1.0710160e+00]\n",
      " [ 5.0497973e-01]\n",
      " [-1.1786929e+00]\n",
      " [ 1.2218797e+00]\n",
      " [ 1.6815662e-01]\n",
      " [-7.6041818e-02]\n",
      " [ 5.3146785e-01]\n",
      " [ 1.0472429e-01]\n",
      " [-9.1920376e-01]\n",
      " [-6.2820888e-01]\n",
      " [-3.4786463e-03]\n",
      " [ 5.3324550e-01]\n",
      " [-4.3436939e-01]\n",
      " [-2.6074028e-01]\n",
      " [ 3.7150621e-02]\n",
      " [-7.5084054e-01]\n",
      " [-1.0349655e-01]\n",
      " [-7.9523540e-01]\n",
      " [-1.5150582e+00]\n",
      " [ 7.5738060e-01]\n",
      " [ 7.0012987e-01]\n",
      " [ 1.8179897e+00]\n",
      " [ 1.6450700e+00]\n",
      " [-5.9026998e-01]\n",
      " [-9.6845794e-01]\n",
      " [-9.5128620e-01]\n",
      " [-7.4864316e-01]\n",
      " [-1.6934334e+00]\n",
      " [ 9.1090775e-01]\n",
      " [-1.2440948e+00]\n",
      " [-8.6590672e-01]\n",
      " [-1.5156842e+00]\n",
      " [-2.5989876e+00]\n",
      " [ 1.2444792e+00]\n",
      " [ 2.7399821e+00]\n",
      " [ 2.2259383e+00]\n",
      " [ 3.0071168e+00]\n",
      " [-3.6425915e+00]\n",
      " [ 3.7722192e+00]\n",
      " [-3.8646779e+00]\n",
      " [ 4.5628133e+00]]\n",
      "Round: 48\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007125922408574102\n",
      "2 Fail: due to tiny learning rate( 0.008551106890288922 )\n",
      "Stop, Learning Goal = 1.2582529\n",
      "[[-0.8692641 ]\n",
      " [-1.0689526 ]\n",
      " [ 0.17158082]\n",
      " [ 0.4443417 ]\n",
      " [-0.5871105 ]\n",
      " [ 1.0432622 ]\n",
      " [-0.31076857]\n",
      " [ 0.4956979 ]\n",
      " [ 0.2703767 ]\n",
      " [-0.10886082]\n",
      " [-1.172689  ]\n",
      " [ 1.2832586 ]\n",
      " [-0.85298693]\n",
      " [ 0.05468145]\n",
      " [ 0.47260043]\n",
      " [-0.63243175]\n",
      " [ 0.11172071]\n",
      " [-0.4940444 ]\n",
      " [ 0.57597995]\n",
      " [-0.26634476]\n",
      " [ 0.04637685]\n",
      " [-0.04097769]\n",
      " [-0.72327423]\n",
      " [-1.4139119 ]\n",
      " [-0.7727158 ]\n",
      " [ 0.78572345]\n",
      " [ 0.67642343]\n",
      " [ 1.8478391 ]\n",
      " [ 1.5856714 ]\n",
      " [-0.8067249 ]\n",
      " [-0.5957341 ]\n",
      " [-0.8458612 ]\n",
      " [-0.7421248 ]\n",
      " [ 0.84056103]\n",
      " [-0.7139003 ]\n",
      " [-1.733391  ]\n",
      " [-1.2776031 ]\n",
      " [-1.3511224 ]\n",
      " [-2.4038808 ]\n",
      " [ 2.6119092 ]\n",
      " [ 1.1695621 ]\n",
      " [ 2.0128994 ]\n",
      " [ 2.847322  ]\n",
      " [-3.535389  ]\n",
      " [ 3.4714918 ]\n",
      " [-3.5741754 ]\n",
      " [ 4.3526936 ]\n",
      " [-4.9844203 ]]\n",
      "Round: 49\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008551106890288922\n",
      "2 Keep learning at learning rate = 0.010261328268346706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Fail: due to tiny learning rate( 0.007182929787842694 )\n",
      "Stop, Learning Goal = 1.2930782\n",
      "[[-0.8627469 ]\n",
      " [-1.0921657 ]\n",
      " [ 0.19845086]\n",
      " [ 0.33733702]\n",
      " [ 1.0220032 ]\n",
      " [ 0.44955122]\n",
      " [ 0.49599272]\n",
      " [-0.1275329 ]\n",
      " [-0.30408853]\n",
      " [-1.1272485 ]\n",
      " [-0.5840635 ]\n",
      " [-0.8468544 ]\n",
      " [ 0.10471827]\n",
      " [ 0.40100747]\n",
      " [-0.52048564]\n",
      " [ 1.3454742 ]\n",
      " [-0.63204235]\n",
      " [ 0.11373776]\n",
      " [ 0.58541894]\n",
      " [-0.3082897 ]\n",
      " [ 0.04247147]\n",
      " [ 0.06470758]\n",
      " [-0.7323467 ]\n",
      " [-1.316411  ]\n",
      " [-0.7934441 ]\n",
      " [ 0.6654671 ]\n",
      " [ 0.8027316 ]\n",
      " [ 1.8259375 ]\n",
      " [-0.7321308 ]\n",
      " [ 1.541234  ]\n",
      " [-0.77171665]\n",
      " [-0.6271625 ]\n",
      " [-0.6057115 ]\n",
      " [ 0.82086056]\n",
      " [-0.741857  ]\n",
      " [-1.7767925 ]\n",
      " [-1.2925675 ]\n",
      " [-2.2991366 ]\n",
      " [-1.2259569 ]\n",
      " [ 2.5431776 ]\n",
      " [ 1.1243777 ]\n",
      " [ 1.873688  ]\n",
      " [ 2.7107968 ]\n",
      " [-3.4701152 ]\n",
      " [ 3.2605119 ]\n",
      " [-3.3922799 ]\n",
      " [ 4.220163  ]\n",
      " [-4.7810197 ]\n",
      " [ 6.214893  ]]\n",
      "Round: 50\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007182929787842694\n",
      "2 Fail: due to tiny learning rate( 0.008619515745411232 )\n",
      "Stop, Learning Goal = 1.3398587\n",
      "[[ 0.4023361 ]\n",
      " [ 0.22945222]\n",
      " [-0.877795  ]\n",
      " [-1.1403767 ]\n",
      " [ 0.97909224]\n",
      " [ 0.48456714]\n",
      " [ 0.553848  ]\n",
      " [-0.13118008]\n",
      " [-1.0201511 ]\n",
      " [ 0.26266214]\n",
      " [-0.30453697]\n",
      " [ 0.176267  ]\n",
      " [-0.5936204 ]\n",
      " [-0.8794453 ]\n",
      " [-0.56582487]\n",
      " [-0.5876601 ]\n",
      " [ 0.10351881]\n",
      " [ 1.4405326 ]\n",
      " [-0.35620776]\n",
      " [ 0.6358477 ]\n",
      " [ 0.14671978]\n",
      " [-1.1815716 ]\n",
      " [-0.7420119 ]\n",
      " [ 0.13682017]\n",
      " [-0.8479856 ]\n",
      " [ 0.6134523 ]\n",
      " [ 0.7959907 ]\n",
      " [ 1.7318373 ]\n",
      " [-0.62963295]\n",
      " [ 1.4778713 ]\n",
      " [-0.69733894]\n",
      " [-0.6826551 ]\n",
      " [-0.44250086]\n",
      " [ 0.78138125]\n",
      " [-0.80739415]\n",
      " [-1.0498413 ]\n",
      " [-2.1552057 ]\n",
      " [-1.8624607 ]\n",
      " [-1.3086916 ]\n",
      " [ 2.4375486 ]\n",
      " [ 1.0679933 ]\n",
      " [ 1.6561927 ]\n",
      " [ 2.4638321 ]\n",
      " [-3.3812132 ]\n",
      " [ 2.9347682 ]\n",
      " [-3.0859466 ]\n",
      " [ 4.0462    ]\n",
      " [-4.52032   ]\n",
      " [ 5.9105635 ]\n",
      " [ 4.932856  ]]\n",
      "Round: 51\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008619515745411232\n",
      "2 Keep learning at learning rate = 0.010343418894493478\n",
      "3 Fail: due to tiny learning rate( 0.0072403932261454335 )\n",
      "Stop, Learning Goal = 1.3782172\n",
      "[[ 0.43858126]\n",
      " [ 0.2621862 ]\n",
      " [-0.84535336]\n",
      " [ 0.98385155]\n",
      " [ 0.22587904]\n",
      " [-0.94939804]\n",
      " [-1.1132976 ]\n",
      " [ 0.21199551]\n",
      " [-0.09269318]\n",
      " [ 0.5594357 ]\n",
      " [-0.30242118]\n",
      " [-0.6025661 ]\n",
      " [-0.5574546 ]\n",
      " [ 0.5995095 ]\n",
      " [-0.90805495]\n",
      " [ 0.10288957]\n",
      " [ 0.19621602]\n",
      " [-0.35297427]\n",
      " [-0.54113007]\n",
      " [-1.1046628 ]\n",
      " [ 0.68819946]\n",
      " [ 1.500045  ]\n",
      " [-0.72285545]\n",
      " [ 0.19625953]\n",
      " [ 0.6102897 ]\n",
      " [-0.8966515 ]\n",
      " [ 0.7668073 ]\n",
      " [ 1.658873  ]\n",
      " [-0.5117701 ]\n",
      " [ 1.4483987 ]\n",
      " [-0.64480436]\n",
      " [-0.34999785]\n",
      " [-0.6789049 ]\n",
      " [-0.9529749 ]\n",
      " [ 0.74568176]\n",
      " [-2.0521476 ]\n",
      " [-0.822857  ]\n",
      " [ 2.355639  ]\n",
      " [-1.2802557 ]\n",
      " [-1.8619577 ]\n",
      " [ 1.0544626 ]\n",
      " [ 1.5170377 ]\n",
      " [ 2.3368387 ]\n",
      " [ 2.7646866 ]\n",
      " [-3.2521656 ]\n",
      " [-2.89529   ]\n",
      " [-4.358345  ]\n",
      " [ 3.9635656 ]\n",
      " [ 5.7214656 ]\n",
      " [ 4.663692  ]\n",
      " [-5.9796906 ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "#Step1. Pick up n cases to set up an acceptable SLFN with 1 hidden node\n",
    "n = 1\n",
    "lts_x_error = sess.run(residual, feed_dict={xs: x_data, yc: y_data})\n",
    "Output = sess.run(OutputLOutput, feed_dict={xs: x_data, yc: y_data})\n",
    "lts_x_data, lts_y_data = lts(n, lts_x_error, x_data, y_data)\n",
    "print(\"Round:\", n, \"\\nInitial model.\")\n",
    "n = n + 1\n",
    "\n",
    "#Step1.1 Initial SLFN model\n",
    "sess.run(train, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "Output = sess.run(OutputLOutput, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "Error = sess.run(LossFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "iniHWeights = sess.run(HWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "iniHThreshold = sess.run(HThreshold, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "iniOWeights = sess.run(OWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "iniOThreshold = sess.run(OThreshold, feed_dict={xs: lts_x_data, yc: lts_y_data}) \n",
    "\n",
    "#Step2. Add another case into I(n)\n",
    "  #Stopping Criteria1: n = dataVolume\n",
    "while n <= dataVolume:\n",
    "    #Save previous error, weights & thresholds\n",
    "    preError = Error\n",
    "    preHWeights = sess.run(HWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "    preHThreshold = sess.run(HThreshold, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "    preOWeights = sess.run(OWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "    preOThreshold = sess.run(OThreshold, feed_dict={xs: lts_x_data, yc: lts_y_data})    \n",
    "    lts_x_error = sess.run(residual, feed_dict={xs: x_data, yc: y_data})\n",
    "    lts_x_data, lts_y_data = lts(n, lts_x_error, x_data, y_data)\n",
    "    #debugging\n",
    "    print(\"Round:\", n)\n",
    "    #print(lts_x_data)\n",
    "    #print(lts_y_data)\n",
    "    #print(preError, preHThreshold, preHWeights, preOThreshold, preOWeights, sep = \"\\n\")\n",
    "    n = n + 1\n",
    "\n",
    "#Step3. Whether I(n) satisfying the Learning Goal?\n",
    "    LearningGoal = sess.run(LearningGoalFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "    #Stopping Criteria2: LearningGoal <= 0.1\n",
    "    if LearningGoal <= 0.1:\n",
    "        print(\"No out-lier.\")\n",
    "        continue\n",
    "        \n",
    "#Step4. Weight-Tuning Mechanism: Creating a new SLFN model\n",
    "    else:\n",
    "        print(\"Out-lier detection!\")\n",
    "        time = 0\n",
    "        #Step5-1. Stopping Criteria(1): LearningGoal <= 0.1\n",
    "        while LearningGoal > 0.1:\n",
    "            time = time + 1\n",
    "            #train a new model\n",
    "            sess.run(train, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "            Output = sess.run(OutputLOutput, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "            if Error > preError:\n",
    "\n",
    "        #Step5-2. Stopping Criteria(2): Learning-rate\n",
    "                if LearningRate < 0.01:\n",
    "                    print(time, \"Fail: due to tiny learning rate(\", LearningRate, \")\")\n",
    "                    #restore weights & thresholds (Step.6 Cramming & Softening Mechanism... to be updated)\n",
    "                    #sess.run(tf.assign(HWeights, iniHWeights))\n",
    "                    #sess.run(tf.assign(HThreshold, iniHThreshold))\n",
    "                    #sess.run(tf.assign(OWeights, iniOWeights))\n",
    "                    #sess.run(tf.assign(OThreshold, iniOThreshold)) \n",
    "                    break\n",
    "                else:\n",
    "                    print(time, \"Keep learning at learning rate =\", LearningRate)\n",
    "                    LearningRate = LearningRate * 0.7\n",
    "                    sess.run(tf.assign(HWeights, preHWeights))\n",
    "                    sess.run(tf.assign(HThreshold, preHThreshold))\n",
    "                    sess.run(tf.assign(OWeights, preOWeights))\n",
    "                    sess.run(tf.assign(OThreshold, preOThreshold)) \n",
    "\n",
    "            else:\n",
    "                print(time, \"Keep learning at learning rate =\", LearningRate)\n",
    "                LearningRate = LearningRate * 1.2\n",
    "                Error = sess.run(LossFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        print(\"Stop, Learning Goal =\", LearningGoal)\n",
    "        sess.run(train, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        Output = sess.run(OutputLOutput, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        Error = sess.run(LossFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        LearningGoal = sess.run(LearningGoalFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        print(Output)\n",
    "        \n",
    "            #debugging\n",
    "        #Weights = sess.run(OWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        #LearningGoal = sess.run(LearningGoalFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        #LearningRateArr.append(LearningRate)\n",
    "        #ErrorArr.append(Error)\n",
    "        #print(\"Time =\", time, \" Learning Rate =\", LearningRate, \" Error =\", Error)\n",
    "        #print(\"Weights =\", Weights)\n",
    "        #print(\"Output =\", Output)\n",
    "        #LearningRateGraph = plt.plot(LearningRateArr)\n",
    "        #print(\"Learning Rate\", LearningRateGraph)\n",
    "        #ErrorGraph = plt.plot(ErrorArr)\n",
    "        #print(\"Error\", ErrorGraph)\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go to Terminal\n",
    "#enter:\n",
    "    #cd ~user\n",
    "    #tensorboard --logdir=showmethetensorboard --host=127.0.0.1\n",
    "#Copy the URL to your browser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
