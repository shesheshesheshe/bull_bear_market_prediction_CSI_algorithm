{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.002390</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>-0.002171</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.002484</td>\n",
       "      <td>-0.002170</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.002925</td>\n",
       "      <td>-0.002657</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.003050</td>\n",
       "      <td>-0.002783</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>-0.001840</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>477</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>478</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>479</td>\n",
       "      <td>-0.001698</td>\n",
       "      <td>-0.001352</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -0.002390 -0.002091  0.001010 -0.002171  0.000091  0.000114  0.000548   \n",
       "1   -0.002484 -0.002170  0.000752  0.000790  0.000086  0.000113  0.000554   \n",
       "2   -0.002752 -0.002469  0.000998  0.002989  0.000087  0.000114  0.000555   \n",
       "3   -0.002925 -0.002657  0.001240  0.003282  0.000092  0.000116  0.000563   \n",
       "4   -0.003050 -0.002783  0.001476  0.000550  0.000090  0.000116  0.000602   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "475 -0.001887 -0.001211  0.000661 -0.000645  0.001544  0.001539  0.000090   \n",
       "476 -0.001840 -0.001211  0.000724 -0.000030  0.001526  0.001546  0.000089   \n",
       "477 -0.002028 -0.001431  0.000122  0.002421  0.001551  0.001550  0.000089   \n",
       "478 -0.001761 -0.001289  0.000528  0.000795  0.001549  0.001558  0.000090   \n",
       "479 -0.001698 -0.001352  0.000317  0.000710  0.001572  0.001572  0.000102   \n",
       "\n",
       "           7         8         9         10        11  12  \n",
       "0    0.000718  0.000021  0.000004  0.001011  0.000984  -1  \n",
       "1    0.000679  0.000020  0.000003  0.001013  0.000981  -1  \n",
       "2    0.000621  0.000021  0.000004  0.001038  0.000988  -1  \n",
       "3    0.000485  0.000026  0.000006  0.001069  0.001009   1  \n",
       "4    0.000446  0.000026  0.000007  0.001051  0.001009   1  \n",
       "..        ...       ...       ...       ...       ...  ..  \n",
       "475  0.000369  0.001451  0.000685  0.001134  0.001385   1  \n",
       "476  0.000272  0.001480  0.000644  0.001229  0.001433   1  \n",
       "477  0.000233  0.001513  0.000688  0.001356  0.001481   1  \n",
       "478  0.000233  0.001557  0.000923  0.001439  0.001572   1  \n",
       "479  0.000252  0.001572  0.000633  0.001285  0.001546   1  \n",
       "\n",
       "[480 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "!rm -rf ./logs/ \n",
    "import sys\n",
    "\n",
    "train_all = pd.read_csv(\"tsaih_train_all.csv\",na_values=['null'],index_col=False, header=None, infer_datetime_format=True)\n",
    "#rule_base_weights = pd.read_csv(\"\",na_values=['null'],index_col=False, header=None, infer_datetime_format=True)\n",
    "train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-144686616442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataVolume\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhiddenSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of input node, m =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of hidden node, p =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddenSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of inputs, q =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataVolume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_all' is not defined"
     ]
    }
   ],
   "source": [
    "dataVolume, inputSize = train_all.shape\n",
    "hiddenSize = 1\n",
    "print(\"Number of input node, m =\", inputSize)\n",
    "print(\"Number of hidden node, p =\", hiddenSize)\n",
    "print(\"Number of inputs, q =\", dataVolume)\n",
    "x_data = 2 * np.random.random_sample((dataVolume, inputSize)) -1\n",
    "y_data = 2 * np.random.random_sample((dataVolume, 1)) -1\n",
    "xs = tf.placeholder(tf.float64)\n",
    "yc = tf.placeholder(tf.float64)\n",
    "asarray(line.split(), dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f79dcf715852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#Step 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mHiddenLOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHWeights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHThreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddenSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mOutputLOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOWeights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOThreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHiddenLOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddenSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xs' is not defined"
     ]
    }
   ],
   "source": [
    "def add_layer(inputs, input_size, output_size, activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([input_size, output_size]))\n",
    "    threshold = tf.Variable(tf.zeros([1, output_size]) + 0.1)\n",
    "    Wx_plus_b = tf.matmul(inputs, Weights) + threshold\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs, Weights, threshold\n",
    "\n",
    "LearningRate = 0.01\n",
    "RegularizationTerm = 0.001\n",
    "LearningRateArr = []\n",
    "ErrorArr = []\n",
    "\n",
    "#Step 1\n",
    "HiddenLOutput, HWeights, HThreshold = add_layer(xs, inputSize, hiddenSize, activation_function = tf.tanh)\n",
    "OutputLOutput, OWeights, OThreshold = add_layer(HiddenLOutput, hiddenSize, 1, activation_function = None)\n",
    "\n",
    "\n",
    "#Forwarding (Activation Function & Regulation term)\n",
    "LossFunction = tf.reduce_mean(tf.reduce_sum(tf.square(yc - OutputLOutput)\n",
    "                  , reduction_indices=[1])) + tf.math.multiply(RegularizationTerm\n",
    "                  , tf.reduce_sum(tf.square(OWeights)) + tf.reduce_sum(tf.square(HWeights)) + tf.reduce_sum(tf.square(HThreshold))+tf.reduce_sum(tf.square(OThreshold)))\n",
    "\n",
    "#Backwarding by Gradient\n",
    "#Set adjusted Learning Goal\n",
    "train = tf.train.GradientDescentOptimizer(LearningRate).minimize(LossFunction)\n",
    "\n",
    "#LTS\n",
    "residual = tf.square(yc - OutputLOutput)\n",
    "def lts(n, lts_x_error, x_data, y_data):\n",
    "    lts_x_data = []\n",
    "    lts_y_data = []\n",
    "    #index_list = []\n",
    "    for i in range(n):\n",
    "        index = np.where(lts_x_error == lts_x_error.min())\n",
    "        #index_list.append(index[0])\n",
    "        lts_x_error[index[0]] = lts_x_error.max() + 1\n",
    "        lts_x_data.extend(x_data[index[0]])\n",
    "        lts_y_data.extend(y_data[index[0]])\n",
    "    return lts_x_data, lts_y_data\n",
    "\n",
    "#Learning Goal\n",
    "LearningGoalFunction = tf.reduce_mean(tf.reduce_sum(tf.math.abs(yc - OutputLOutput), reduction_indices=[1]))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 1 \n",
      "Initial model.\n",
      "Round: 2\n",
      "No out-lier.\n",
      "Round: 3\n",
      "No out-lier.\n",
      "Round: 4\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.01\n",
      "2 Keep learning at learning rate = 0.012\n",
      "3 Fail: due to tiny learning rate( 0.0084 )\n",
      "Stop, Learning Goal = 0.11341385\n",
      "[[ 0.6112622 ]\n",
      " [-0.69528615]\n",
      " [-0.36639357]\n",
      " [ 0.3393867 ]]\n",
      "Round: 5\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.0084\n",
      "2 Keep learning at learning rate = 0.010079999999999999\n",
      "3 Fail: due to tiny learning rate( 0.007055999999999999 )\n",
      "Stop, Learning Goal = 0.10361793\n",
      "[[ 0.6013023 ]\n",
      " [-0.6623258 ]\n",
      " [-0.38419467]\n",
      " [ 0.29767972]\n",
      " [-1.0612127 ]]\n",
      "Round: 6\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007055999999999999\n",
      "2 Fail: due to tiny learning rate( 0.008467199999999998 )\n",
      "Stop, Learning Goal = 0.117694475\n",
      "[[-0.65442526]\n",
      " [ 0.5909029 ]\n",
      " [-0.3869648 ]\n",
      " [ 0.25948417]\n",
      " [-1.0099604 ]\n",
      " [-0.81893885]]\n",
      "Round: 7\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008467199999999998\n",
      "2 Keep learning at learning rate = 0.010160639999999997\n",
      "3 Fail: due to tiny learning rate( 0.007112447999999997 )\n",
      "Stop, Learning Goal = 0.17925863\n",
      "[[-0.62185353]\n",
      " [ 0.5719471 ]\n",
      " [-0.40224236]\n",
      " [ 0.25444287]\n",
      " [-0.9341913 ]\n",
      " [-0.7629761 ]\n",
      " [-1.5833498 ]]\n",
      "Round: 8\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007112447999999997\n",
      "2 Fail: due to tiny learning rate( 0.008534937599999995 )\n",
      "Stop, Learning Goal = 0.23897097\n",
      "[[-0.44327   ]\n",
      " [ 0.51596797]\n",
      " [-0.5982029 ]\n",
      " [-0.8981007 ]\n",
      " [ 0.26927587]\n",
      " [-0.70817906]\n",
      " [-1.4337611 ]\n",
      " [ 0.8376408 ]]\n",
      "Round: 9\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008534937599999995\n",
      "2 Keep learning at learning rate = 0.010241925119999993\n",
      "3 Fail: due to tiny learning rate( 0.007169347583999995 )\n",
      "Stop, Learning Goal = 0.28637132\n",
      "[[-0.46824497]\n",
      " [-0.93229204]\n",
      " [-0.6019513 ]\n",
      " [ 0.24123055]\n",
      " [ 0.49524415]\n",
      " [-0.66601235]\n",
      " [-1.4057815 ]\n",
      " [ 0.742287  ]\n",
      " [-0.11975745]]\n",
      "Round: 10\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007169347583999995\n",
      "2 Fail: due to tiny learning rate( 0.008603217100799993 )\n",
      "Stop, Learning Goal = 0.34396505\n",
      "[[-0.4763376 ]\n",
      " [ 0.19116813]\n",
      " [-0.9296463 ]\n",
      " [-0.6658831 ]\n",
      " [-0.5279078 ]\n",
      " [ 0.46741784]\n",
      " [-1.3778679 ]\n",
      " [ 0.6270909 ]\n",
      " [-0.31863678]\n",
      " [ 1.5284297 ]]\n",
      "Round: 11\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008603217100799993\n",
      "2 Keep learning at learning rate = 0.010323860520959991\n",
      "3 Fail: due to tiny learning rate( 0.007226702364671993 )\n",
      "Stop, Learning Goal = 0.3622453\n",
      "[[ 0.21549445]\n",
      " [-0.50722975]\n",
      " [-0.921725  ]\n",
      " [-0.67941076]\n",
      " [-0.50821733]\n",
      " [ 0.45449412]\n",
      " [-1.324553  ]\n",
      " [ 0.54261583]\n",
      " [-0.3989774 ]\n",
      " [ 1.4126759 ]\n",
      " [-1.3737549 ]]\n",
      "Round: 12\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007226702364671993\n",
      "2 Fail: due to tiny learning rate( 0.008672042837606392 )\n",
      "Stop, Learning Goal = 0.40677366\n",
      "[[ 0.2760626 ]\n",
      " [-0.95375144]\n",
      " [-0.5487273 ]\n",
      " [-0.64932936]\n",
      " [ 0.43673742]\n",
      " [-0.5467189 ]\n",
      " [-1.2854799 ]\n",
      " [ 0.4724548 ]\n",
      " [-0.50754493]\n",
      " [ 1.3255507 ]\n",
      " [-1.1746373 ]\n",
      " [-0.7302845 ]]\n",
      "Round: 13\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008672042837606392\n",
      "2 Keep learning at learning rate = 0.01040645140512767\n",
      "3 Fail: due to tiny learning rate( 0.007284515983589368 )\n",
      "Stop, Learning Goal = 0.42247814\n",
      "[[-0.66016114]\n",
      " [-0.9559006 ]\n",
      " [ 0.33262056]\n",
      " [-0.63448685]\n",
      " [-0.59090453]\n",
      " [ 0.39807636]\n",
      " [-1.2525206 ]\n",
      " [ 0.42216808]\n",
      " [-0.55750734]\n",
      " [ 1.2391608 ]\n",
      " [-1.0706675 ]\n",
      " [-0.5509522 ]\n",
      " [ 0.98767096]]\n",
      "Round: 14\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007284515983589368\n",
      "2 Fail: due to tiny learning rate( 0.008741419180307242 )\n",
      "Stop, Learning Goal = 0.4446709\n",
      "[[-0.64738417]\n",
      " [-0.61338615]\n",
      " [-0.94563174]\n",
      " [ 0.4012467 ]\n",
      " [-0.71669364]\n",
      " [ 0.35951903]\n",
      " [-1.2087803 ]\n",
      " [ 0.37421754]\n",
      " [-0.65152276]\n",
      " [ 1.1163459 ]\n",
      " [-0.94685376]\n",
      " [-0.31402943]\n",
      " [ 0.68249226]\n",
      " [-1.0571451 ]]\n",
      "Round: 15\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008741419180307242\n",
      "2 Keep learning at learning rate = 0.010489703016368689\n",
      "3 Fail: due to tiny learning rate( 0.007342792111458081 )\n",
      "Stop, Learning Goal = 0.44430712\n",
      "[[-0.6352023 ]\n",
      " [-0.5615954 ]\n",
      " [-0.91889006]\n",
      " [ 0.43475002]\n",
      " [-1.1567396 ]\n",
      " [ 0.36068952]\n",
      " [ 0.37060314]\n",
      " [-0.7511924 ]\n",
      " [-0.6859878 ]\n",
      " [ 1.034074  ]\n",
      " [-0.1866983 ]\n",
      " [-0.8829579 ]\n",
      " [ 0.51921743]\n",
      " [-0.92708856]\n",
      " [-0.7981687 ]]\n",
      "Round: 16\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007342792111458081\n",
      "2 Fail: due to tiny learning rate( 0.008811350533749698 )\n",
      "Stop, Learning Goal = 0.461635\n",
      "[[-0.5987915 ]\n",
      " [-0.8773242 ]\n",
      " [-0.42320597]\n",
      " [-1.1077987 ]\n",
      " [ 0.46369183]\n",
      " [ 0.38770694]\n",
      " [ 0.35565794]\n",
      " [-0.75599277]\n",
      " [-0.73688185]\n",
      " [ 0.9237395 ]\n",
      " [-0.0386187 ]\n",
      " [-0.83273554]\n",
      " [ 0.43316996]\n",
      " [-0.75347716]\n",
      " [-0.5466732 ]\n",
      " [-2.0048144 ]]\n",
      "Round: 17\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008811350533749698\n",
      "2 Keep learning at learning rate = 0.010573620640499637\n",
      "3 Fail: due to tiny learning rate( 0.007401534448349745 )\n",
      "Stop, Learning Goal = 0.4585645\n",
      "[[-0.5966802 ]\n",
      " [-0.8204368 ]\n",
      " [-1.0828918 ]\n",
      " [ 0.83937484]\n",
      " [-0.7851718 ]\n",
      " [ 0.3954668 ]\n",
      " [ 0.00727667]\n",
      " [-0.29878676]\n",
      " [ 0.33216816]\n",
      " [ 0.47837335]\n",
      " [-0.6632878 ]\n",
      " [-0.79343146]\n",
      " [ 0.42171198]\n",
      " [-0.6772438 ]\n",
      " [-0.41241056]\n",
      " [-1.8438584 ]\n",
      " [-1.6803391 ]]\n",
      "Round: 18\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007401534448349745\n",
      "2 Fail: due to tiny learning rate( 0.008881841338019694 )\n",
      "Stop, Learning Goal = 0.49996594\n",
      "[[-0.56031835]\n",
      " [-0.7746403 ]\n",
      " [-1.0399541 ]\n",
      " [ 0.77034545]\n",
      " [ 0.16116728]\n",
      " [-0.8427817 ]\n",
      " [ 0.3944407 ]\n",
      " [-0.61008275]\n",
      " [ 0.2954042 ]\n",
      " [ 0.49955785]\n",
      " [-0.23560931]\n",
      " [-0.7007514 ]\n",
      " [ 0.40251863]\n",
      " [-0.49536687]\n",
      " [-0.34227633]\n",
      " [-1.6117612 ]\n",
      " [-1.4812527 ]\n",
      " [-1.2904173 ]]\n",
      "Round: 19\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008881841338019694\n",
      "2 Keep learning at learning rate = 0.010658209605623631\n",
      "3 Fail: due to tiny learning rate( 0.007460746723936542 )\n",
      "Stop, Learning Goal = 0.4922395\n",
      "[[ 0.2421242 ]\n",
      " [-0.54281074]\n",
      " [ 0.76267725]\n",
      " [-0.9946303 ]\n",
      " [-0.73698574]\n",
      " [-0.837829  ]\n",
      " [-0.57853955]\n",
      " [ 0.2912336 ]\n",
      " [ 0.4023826 ]\n",
      " [ 0.53749114]\n",
      " [-0.6431665 ]\n",
      " [-0.23030734]\n",
      " [ 0.36533648]\n",
      " [-0.41325575]\n",
      " [-0.26798362]\n",
      " [-1.5136318 ]\n",
      " [-1.3930418 ]\n",
      " [-1.0297661 ]\n",
      " [-1.8841078 ]]\n",
      "Round: 20\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007460746723936542\n",
      "2 Fail: due to tiny learning rate( 0.00895289606872385 )\n",
      "Stop, Learning Goal = 0.52384603\n",
      "[[-0.91597146]\n",
      " [ 0.77427405]\n",
      " [ 0.2826649 ]\n",
      " [-0.53977334]\n",
      " [-0.8112851 ]\n",
      " [-0.6776807 ]\n",
      " [-0.5044469 ]\n",
      " [ 0.2778818 ]\n",
      " [ 0.44871658]\n",
      " [-0.56678313]\n",
      " [ 0.5846309 ]\n",
      " [-0.19825377]\n",
      " [ 0.32251173]\n",
      " [-0.36451423]\n",
      " [-0.13152058]\n",
      " [-1.3861223 ]\n",
      " [-1.2328233 ]\n",
      " [-0.7855516 ]\n",
      " [-1.5581254 ]\n",
      " [-1.7981331 ]]\n",
      "Round: 21\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00895289606872385\n",
      "2 Keep learning at learning rate = 0.010743475282468619\n",
      "3 Fail: due to tiny learning rate( 0.007520432697728032 )\n",
      "Stop, Learning Goal = 0.5321629\n",
      "[[ 0.7908956 ]\n",
      " [-0.86709213]\n",
      " [-0.5563625 ]\n",
      " [-0.48235297]\n",
      " [ 0.3105471 ]\n",
      " [-0.793028  ]\n",
      " [ 0.4288175 ]\n",
      " [ 0.25398195]\n",
      " [-0.51146996]\n",
      " [-0.6369519 ]\n",
      " [ 0.62939584]\n",
      " [-0.31909668]\n",
      " [ 0.2176459 ]\n",
      " [-0.2903828 ]\n",
      " [-0.09237169]\n",
      " [-1.3436496 ]\n",
      " [-0.6608527 ]\n",
      " [-1.160724  ]\n",
      " [-1.35519   ]\n",
      " [-1.6647302 ]\n",
      " [ 0.840585  ]]\n",
      "Round: 22\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007520432697728032\n",
      "2 Fail: due to tiny learning rate( 0.009024519237273638 )\n",
      "Stop, Learning Goal = 0.5485192\n",
      "[[-0.43248713]\n",
      " [-0.51810044]\n",
      " [ 0.8360802 ]\n",
      " [-0.7880444 ]\n",
      " [ 0.34942636]\n",
      " [-0.44128525]\n",
      " [ 0.18699718]\n",
      " [-0.78798866]\n",
      " [ 0.4160543 ]\n",
      " [-0.6137459 ]\n",
      " [ 0.14337862]\n",
      " [-0.37331003]\n",
      " [-0.2672314 ]\n",
      " [ 0.6689571 ]\n",
      " [-0.0705328 ]\n",
      " [-1.2610326 ]\n",
      " [-0.46386886]\n",
      " [-1.0674565 ]\n",
      " [-1.1223396 ]\n",
      " [ 0.51935065]\n",
      " [-1.4803436 ]\n",
      " [-0.92041886]]\n",
      "Round: 23\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009024519237273638\n",
      "2 Keep learning at learning rate = 0.010829423084728366\n",
      "3 Fail: due to tiny learning rate( 0.0075805961593098554 )\n",
      "Stop, Learning Goal = 0.5568285\n",
      "[[-0.40262973]\n",
      " [-0.42091227]\n",
      " [ 0.19408952]\n",
      " [-0.5048772 ]\n",
      " [ 0.8221897 ]\n",
      " [ 0.3863938 ]\n",
      " [-0.79243207]\n",
      " [-0.73757106]\n",
      " [ 0.42831826]\n",
      " [-0.554052  ]\n",
      " [ 0.1023327 ]\n",
      " [-0.36979443]\n",
      " [-0.21855493]\n",
      " [ 0.6695504 ]\n",
      " [-0.4037205 ]\n",
      " [-0.00373401]\n",
      " [-1.1877295 ]\n",
      " [-1.0081038 ]\n",
      " [-0.9942745 ]\n",
      " [ 0.38065565]\n",
      " [-1.382543  ]\n",
      " [-0.8697692 ]\n",
      " [-1.379895  ]]\n",
      "Round: 24\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.0075805961593098554\n",
      "2 Fail: due to tiny learning rate( 0.009096715391171826 )\n",
      "Stop, Learning Goal = 0.5935614\n",
      "[[-0.4092915 ]\n",
      " [-0.39514208]\n",
      " [ 0.21022499]\n",
      " [-0.50217545]\n",
      " [ 0.8065869 ]\n",
      " [-0.8004048 ]\n",
      " [ 0.46009105]\n",
      " [ 0.42346856]\n",
      " [-0.6926974 ]\n",
      " [ 0.07836676]\n",
      " [-0.3879345 ]\n",
      " [-0.17017734]\n",
      " [-0.51908004]\n",
      " [ 0.0369972 ]\n",
      " [-0.31775022]\n",
      " [ 0.64365137]\n",
      " [-1.0890126 ]\n",
      " [-0.95984125]\n",
      " [-0.81843305]\n",
      " [ 0.23060274]\n",
      " [-1.2777877 ]\n",
      " [-0.7946773 ]\n",
      " [-1.1424265 ]\n",
      " [ 2.8611147 ]]\n",
      "Round: 25\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009096715391171826\n",
      "2 Keep learning at learning rate = 0.01091605846940619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Fail: due to tiny learning rate( 0.007641240928584332 )\n",
      "Stop, Learning Goal = 0.6128939\n",
      "[[-0.38982892]\n",
      " [-0.39568043]\n",
      " [ 0.78010064]\n",
      " [-0.52402973]\n",
      " [ 0.25444305]\n",
      " [ 0.50216615]\n",
      " [-0.808144  ]\n",
      " [ 0.0806818 ]\n",
      " [ 0.45050013]\n",
      " [-0.13259816]\n",
      " [-0.6778443 ]\n",
      " [-0.39367348]\n",
      " [-0.47532666]\n",
      " [-0.2687943 ]\n",
      " [-1.0403479 ]\n",
      " [ 0.07107878]\n",
      " [ 0.61449647]\n",
      " [-0.9206275 ]\n",
      " [-0.725998  ]\n",
      " [ 0.17029881]\n",
      " [-1.2281038 ]\n",
      " [-0.7964423 ]\n",
      " [-0.90830183]\n",
      " [ 2.7393668 ]\n",
      " [-2.2083552 ]]\n",
      "Round: 26\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007641240928584332\n",
      "2 Fail: due to tiny learning rate( 0.009169489114301198 )\n",
      "Stop, Learning Goal = 0.64681846\n",
      "[[-0.3934164 ]\n",
      " [-0.4010018 ]\n",
      " [ 0.7919213 ]\n",
      " [-0.570262  ]\n",
      " [ 0.54130733]\n",
      " [ 0.30808818]\n",
      " [-0.7853683 ]\n",
      " [ 0.10924017]\n",
      " [-0.11979973]\n",
      " [ 0.47221297]\n",
      " [-0.4325143 ]\n",
      " [-0.66263103]\n",
      " [-0.24776685]\n",
      " [-0.98730266]\n",
      " [ 0.04345906]\n",
      " [-0.42305458]\n",
      " [ 0.5753567 ]\n",
      " [-0.8668339 ]\n",
      " [-0.6069072 ]\n",
      " [ 0.08704484]\n",
      " [-1.1699239 ]\n",
      " [-0.6559448 ]\n",
      " [-0.7798893 ]\n",
      " [ 2.5305166 ]\n",
      " [-1.9679447 ]\n",
      " [ 1.626788  ]]\n",
      "Round: 27\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009169489114301198\n",
      "2 Keep learning at learning rate = 0.011003386937161437\n",
      "3 Fail: due to tiny learning rate( 0.007702370856013005 )\n",
      "Stop, Learning Goal = 0.6732698\n",
      "[[-0.44051307]\n",
      " [-0.5778758 ]\n",
      " [-0.40081483]\n",
      " [ 0.7874147 ]\n",
      " [ 0.53622955]\n",
      " [-0.7930606 ]\n",
      " [ 0.33330446]\n",
      " [-0.10311092]\n",
      " [-0.5117223 ]\n",
      " [ 0.09402339]\n",
      " [ 0.486315  ]\n",
      " [-0.24835236]\n",
      " [-0.9892426 ]\n",
      " [-0.6725702 ]\n",
      " [ 0.55268675]\n",
      " [ 0.03324811]\n",
      " [-0.40854138]\n",
      " [-0.52782094]\n",
      " [-0.84324735]\n",
      " [-0.00435264]\n",
      " [-1.1279151 ]\n",
      " [-0.50422597]\n",
      " [-0.7786275 ]\n",
      " [ 2.417569  ]\n",
      " [-1.8465067 ]\n",
      " [ 1.5427765 ]\n",
      " [ 2.0345294 ]]\n",
      "Round: 28\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007702370856013005\n",
      "2 Fail: due to tiny learning rate( 0.009242845027215606 )\n",
      "Stop, Learning Goal = 0.70449305\n",
      "[[-0.6035954 ]\n",
      " [-0.4042886 ]\n",
      " [-0.53018695]\n",
      " [ 0.78365666]\n",
      " [ 0.59051365]\n",
      " [-0.6259784 ]\n",
      " [-0.8328412 ]\n",
      " [-0.08516477]\n",
      " [ 0.3951475 ]\n",
      " [ 0.08510275]\n",
      " [-0.28726417]\n",
      " [-0.71095914]\n",
      " [ 0.5096725 ]\n",
      " [-1.0189646 ]\n",
      " [ 0.4656164 ]\n",
      " [-0.44113737]\n",
      " [ 0.03377958]\n",
      " [-0.42672962]\n",
      " [-0.8299679 ]\n",
      " [-0.10672025]\n",
      " [-0.28827673]\n",
      " [-1.0501311 ]\n",
      " [ 2.2358487 ]\n",
      " [-0.7833015 ]\n",
      " [-1.6838429 ]\n",
      " [ 1.406626  ]\n",
      " [ 1.7540684 ]\n",
      " [ 2.583347  ]]\n",
      "Round: 29\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009242845027215606\n",
      "2 Keep learning at learning rate = 0.011091414032658727\n",
      "3 Fail: due to tiny learning rate( 0.007763989822861109 )\n",
      "Stop, Learning Goal = 0.71876866\n",
      "[[-0.596943  ]\n",
      " [ 0.63618743]\n",
      " [-0.36441264]\n",
      " [-0.6257155 ]\n",
      " [ 0.8056371 ]\n",
      " [-0.85336936]\n",
      " [-0.56467295]\n",
      " [-0.09898201]\n",
      " [ 0.1739513 ]\n",
      " [-0.71639204]\n",
      " [ 0.405466  ]\n",
      " [ 0.4053662 ]\n",
      " [-0.4149687 ]\n",
      " [ 0.4812015 ]\n",
      " [-0.9721439 ]\n",
      " [-0.31030115]\n",
      " [ 0.02808741]\n",
      " [-0.42297122]\n",
      " [-0.7376591 ]\n",
      " [-0.0748485 ]\n",
      " [-0.1975488 ]\n",
      " [-0.9502866 ]\n",
      " [ 2.1638656 ]\n",
      " [-1.6153009 ]\n",
      " [-0.7593366 ]\n",
      " [ 1.3163958 ]\n",
      " [ 1.6361731 ]\n",
      " [ 2.3971126 ]\n",
      " [-3.1756573 ]]\n",
      "Round: 30\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007763989822861109\n",
      "2 Fail: due to tiny learning rate( 0.00931678778743333 )\n",
      "Stop, Learning Goal = 0.7732209\n",
      "[[-0.5194522 ]\n",
      " [ 0.66560805]\n",
      " [-0.6827736 ]\n",
      " [-0.31376985]\n",
      " [ 0.8782042 ]\n",
      " [-0.88461924]\n",
      " [-0.5832448 ]\n",
      " [-0.08254662]\n",
      " [ 0.37059066]\n",
      " [-0.7206993 ]\n",
      " [-0.89515996]\n",
      " [-0.3684403 ]\n",
      " [ 0.49931332]\n",
      " [ 0.3802888 ]\n",
      " [ 0.2811794 ]\n",
      " [-0.30126682]\n",
      " [-0.6235502 ]\n",
      " [-0.00714043]\n",
      " [-0.4488608 ]\n",
      " [-0.08811358]\n",
      " [-0.1408307 ]\n",
      " [-0.82576466]\n",
      " [ 2.095034  ]\n",
      " [-1.5783726 ]\n",
      " [-0.652251  ]\n",
      " [ 2.1913276 ]\n",
      " [ 1.4684129 ]\n",
      " [ 1.178877  ]\n",
      " [-2.922585  ]\n",
      " [-3.4905071 ]]\n",
      "Round: 31\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00931678778743333\n",
      "2 Keep learning at learning rate = 0.011180145344919996\n",
      "3 Fail: due to tiny learning rate( 0.007826101741443997 )\n",
      "Stop, Learning Goal = 0.8203962\n",
      "[[-0.72007847]\n",
      " [ 0.6714275 ]\n",
      " [-0.46323657]\n",
      " [-0.8902428 ]\n",
      " [-0.26656246]\n",
      " [ 0.93956625]\n",
      " [-0.08137369]\n",
      " [ 0.37712264]\n",
      " [-0.6120573 ]\n",
      " [-0.8446237 ]\n",
      " [-0.32905525]\n",
      " [-0.7163716 ]\n",
      " [ 0.36437726]\n",
      " [-0.5218128 ]\n",
      " [ 0.5105046 ]\n",
      " [-0.30954695]\n",
      " [ 0.29196858]\n",
      " [-0.43462026]\n",
      " [ 0.00549877]\n",
      " [-0.11008191]\n",
      " [-0.09999126]\n",
      " [-0.719329  ]\n",
      " [ 2.0906203 ]\n",
      " [-1.5455897 ]\n",
      " [-0.6077898 ]\n",
      " [ 2.1594276 ]\n",
      " [ 1.3695116 ]\n",
      " [ 1.1176056 ]\n",
      " [-2.7403848 ]\n",
      " [-3.3532538 ]\n",
      " [-3.109271  ]]\n",
      "Round: 32\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007826101741443997\n",
      "2 Fail: due to tiny learning rate( 0.009391322089732796 )\n",
      "Stop, Learning Goal = 0.88281107\n",
      "[[-0.76059216]\n",
      " [ 0.6751369 ]\n",
      " [-0.8961119 ]\n",
      " [-0.4810984 ]\n",
      " [-0.7811082 ]\n",
      " [-0.06248856]\n",
      " [-0.25008446]\n",
      " [-0.3612072 ]\n",
      " [ 0.34386915]\n",
      " [-0.30865127]\n",
      " [ 0.94177085]\n",
      " [-0.6505483 ]\n",
      " [ 0.32715982]\n",
      " [-0.6987174 ]\n",
      " [ 0.48171657]\n",
      " [-0.32097298]\n",
      " [ 0.2694158 ]\n",
      " [-0.38075513]\n",
      " [ 0.01837105]\n",
      " [-0.01526174]\n",
      " [-0.1579743 ]\n",
      " [-0.5892189 ]\n",
      " [ 2.0648272 ]\n",
      " [-1.4871352 ]\n",
      " [-0.5859218 ]\n",
      " [ 1.2297072 ]\n",
      " [ 2.0905948 ]\n",
      " [ 1.0425658 ]\n",
      " [-2.5033178 ]\n",
      " [-3.2037673 ]\n",
      " [-2.8435686 ]\n",
      " [ 3.3085637 ]]\n",
      "Round: 33\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009391322089732796\n",
      "2 Keep learning at learning rate = 0.011269586507679355\n",
      "3 Fail: due to tiny learning rate( 0.007888710555375548 )\n",
      "Stop, Learning Goal = 0.91506165\n",
      "[[-0.30145139]\n",
      " [ 0.6624205 ]\n",
      " [-0.90271205]\n",
      " [-0.8298604 ]\n",
      " [-0.8164554 ]\n",
      " [-0.48783308]\n",
      " [ 0.30238968]\n",
      " [-0.0441023 ]\n",
      " [-0.24622642]\n",
      " [-0.28344792]\n",
      " [ 0.95683604]\n",
      " [ 0.30714804]\n",
      " [-0.6537078 ]\n",
      " [-0.69469637]\n",
      " [ 0.447196  ]\n",
      " [-0.36948448]\n",
      " [ 0.2288328 ]\n",
      " [ 0.03065689]\n",
      " [-0.3647768 ]\n",
      " [-0.5242295 ]\n",
      " [ 0.03113453]\n",
      " [-0.21922295]\n",
      " [ 2.0329962 ]\n",
      " [-1.4668769 ]\n",
      " [-0.5998594 ]\n",
      " [ 1.0870601 ]\n",
      " [ 1.9978975 ]\n",
      " [ 0.9889942 ]\n",
      " [-2.3938823 ]\n",
      " [-3.119053  ]\n",
      " [-2.713016  ]\n",
      " [ 3.1639357 ]\n",
      " [ 3.2851603 ]]\n",
      "Round: 34\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007888710555375548\n",
      "2 Fail: due to tiny learning rate( 0.009466452666450657 )\n",
      "Stop, Learning Goal = 0.9608898\n",
      "[[-0.19943032]\n",
      " [ 0.61265767]\n",
      " [-0.8994583 ]\n",
      " [ 0.1810346 ]\n",
      " [-0.5222691 ]\n",
      " [-0.24139282]\n",
      " [-0.8287493 ]\n",
      " [-0.02252272]\n",
      " [-0.32821605]\n",
      " [-0.8641038 ]\n",
      " [ 0.28215352]\n",
      " [ 0.9303757 ]\n",
      " [ 0.3346616 ]\n",
      " [-0.6608081 ]\n",
      " [-0.6647314 ]\n",
      " [ 0.22476986]\n",
      " [ 0.01566556]\n",
      " [-0.41725966]\n",
      " [-0.3101568 ]\n",
      " [-0.45263913]\n",
      " [ 0.09536394]\n",
      " [-0.24843857]\n",
      " [ 1.9340625 ]\n",
      " [-1.4561013 ]\n",
      " [ 0.93512654]\n",
      " [-0.6059288 ]\n",
      " [ 1.8676071 ]\n",
      " [ 0.89174175]\n",
      " [-2.2287762 ]\n",
      " [-3.0406575 ]\n",
      " [-2.573496  ]\n",
      " [ 2.8740842 ]\n",
      " [ 2.9196103 ]\n",
      " [ 4.25357   ]]\n",
      "Round: 35\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009466452666450657\n",
      "2 Keep learning at learning rate = 0.011359743199740788\n",
      "3 Fail: due to tiny learning rate( 0.007951820239818552 )\n",
      "Stop, Learning Goal = 0.98897356\n",
      "[[ 5.8030081e-01]\n",
      " [ 1.3624428e-01]\n",
      " [-8.6750281e-01]\n",
      " [-5.2088296e-01]\n",
      " [-3.7161303e-01]\n",
      " [ 4.5277923e-03]\n",
      " [-2.2236879e-01]\n",
      " [-8.3278418e-01]\n",
      " [-1.4459898e-01]\n",
      " [ 3.0066329e-01]\n",
      " [ 2.7341568e-01]\n",
      " [-9.0702891e-01]\n",
      " [ 9.5859438e-01]\n",
      " [-6.3142180e-01]\n",
      " [-6.3310444e-01]\n",
      " [ 2.3208259e-01]\n",
      " [-1.5080124e-03]\n",
      " [-4.2562306e-01]\n",
      " [-4.0682268e-01]\n",
      " [ 1.1696832e-01]\n",
      " [-2.8595948e-01]\n",
      " [-2.7237785e-01]\n",
      " [ 1.8754787e+00]\n",
      " [ 8.6787200e-01]\n",
      " [-1.4491698e+00]\n",
      " [ 1.8387268e+00]\n",
      " [-5.9610230e-01]\n",
      " [ 8.1959856e-01]\n",
      " [-2.1421816e+00]\n",
      " [-2.9345586e+00]\n",
      " [-2.4561560e+00]\n",
      " [ 2.6289465e+00]\n",
      " [ 2.7879601e+00]\n",
      " [ 4.0900059e+00]\n",
      " [-4.8082962e+00]]\n",
      "Round: 36\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007951820239818552\n",
      "2 Fail: due to tiny learning rate( 0.009542184287782262 )\n",
      "Stop, Learning Goal = 1.0401891\n",
      "[[ 5.4024386e-01]\n",
      " [ 4.3706402e-02]\n",
      " [-4.1114414e-01]\n",
      " [-5.2072001e-01]\n",
      " [ 3.4132764e-02]\n",
      " [-2.0305301e-01]\n",
      " [-8.2032406e-01]\n",
      " [ 2.4333598e-01]\n",
      " [-7.9841220e-01]\n",
      " [ 2.8175795e-01]\n",
      " [ 3.6219209e-03]\n",
      " [ 9.9116880e-01]\n",
      " [-9.2435122e-01]\n",
      " [-6.3953984e-01]\n",
      " [-6.0183936e-01]\n",
      " [ 2.5865448e-01]\n",
      " [-3.5123181e-01]\n",
      " [-8.5083395e-03]\n",
      " [-4.0330136e-01]\n",
      " [ 1.6347352e-01]\n",
      " [-3.3326757e-01]\n",
      " [-1.9228031e-01]\n",
      " [ 1.7727908e+00]\n",
      " [ 7.8824627e-01]\n",
      " [-1.4254773e+00]\n",
      " [ 1.7953815e+00]\n",
      " [-5.8949572e-01]\n",
      " [ 6.9320858e-01]\n",
      " [-2.0043051e+00]\n",
      " [-2.7753685e+00]\n",
      " [ 2.3211257e+00]\n",
      " [-2.2375674e+00]\n",
      " [ 2.5856659e+00]\n",
      " [ 3.8582990e+00]\n",
      " [-4.6051736e+00]\n",
      " [-3.9268253e+00]]\n",
      "Round: 37\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009542184287782262\n",
      "2 Keep learning at learning rate = 0.011450621145338714\n",
      "3 Fail: due to tiny learning rate( 0.0080154348017371 )\n",
      "Stop, Learning Goal = 1.0673877\n",
      "[[-0.46795136]\n",
      " [ 0.01864742]\n",
      " [ 0.19426177]\n",
      " [ 0.5023217 ]\n",
      " [-0.19246419]\n",
      " [-0.5249893 ]\n",
      " [-0.7929694 ]\n",
      " [-0.00867648]\n",
      " [-0.77442324]\n",
      " [ 0.27922112]\n",
      " [-0.95334476]\n",
      " [-0.65299124]\n",
      " [ 1.0322099 ]\n",
      " [-0.29393154]\n",
      " [ 0.08968405]\n",
      " [-0.55704546]\n",
      " [ 0.27887744]\n",
      " [ 0.1967702 ]\n",
      " [-0.44016987]\n",
      " [-0.00792296]\n",
      " [-0.37896448]\n",
      " [-0.14916225]\n",
      " [ 1.6668798 ]\n",
      " [ 0.6991467 ]\n",
      " [ 1.7599094 ]\n",
      " [-1.4039356 ]\n",
      " [ 0.5756026 ]\n",
      " [-0.5829921 ]\n",
      " [-1.9329253 ]\n",
      " [-2.6846209 ]\n",
      " [ 2.1564734 ]\n",
      " [-2.117201  ]\n",
      " [ 2.4729629 ]\n",
      " [ 3.666778  ]\n",
      " [-4.469675  ]\n",
      " [-3.7646184 ]\n",
      " [ 3.716066  ]]\n",
      "Round: 38\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.0080154348017371\n",
      "2 Fail: due to tiny learning rate( 0.00961852176208452 )\n",
      "Stop, Learning Goal = 1.106973\n",
      "[[ 0.15663967]\n",
      " [-0.52364135]\n",
      " [-0.18029556]\n",
      " [ 0.01243865]\n",
      " [-0.5285562 ]\n",
      " [-0.7946974 ]\n",
      " [ 0.43222073]\n",
      " [ 0.2601702 ]\n",
      " [-0.71308434]\n",
      " [-0.03919676]\n",
      " [-0.64530706]\n",
      " [-0.2040165 ]\n",
      " [-0.99497354]\n",
      " [ 1.0833224 ]\n",
      " [ 0.23242131]\n",
      " [-0.51842964]\n",
      " [ 0.29807875]\n",
      " [-0.45672753]\n",
      " [ 0.24886331]\n",
      " [-0.00572434]\n",
      " [-0.46923473]\n",
      " [-0.08750275]\n",
      " [ 1.5381825 ]\n",
      " [ 0.55359125]\n",
      " [ 0.44841167]\n",
      " [ 1.7063351 ]\n",
      " [-1.3669024 ]\n",
      " [-1.8348505 ]\n",
      " [-0.5454643 ]\n",
      " [ 1.9336342 ]\n",
      " [-2.5394876 ]\n",
      " [-1.9600751 ]\n",
      " [ 2.335189  ]\n",
      " [ 3.401415  ]\n",
      " [-4.283813  ]\n",
      " [-3.5330331 ]\n",
      " [ 3.3165436 ]\n",
      " [-4.400166  ]]\n",
      "Round: 39\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00961852176208452\n",
      "2 Keep learning at learning rate = 0.011542226114501423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Fail: due to tiny learning rate( 0.008079558280150995 )\n",
      "Stop, Learning Goal = 1.1228062\n",
      "[[ 0.14742371]\n",
      " [-0.14926037]\n",
      " [-0.5180038 ]\n",
      " [ 0.02548146]\n",
      " [-0.5431279 ]\n",
      " [-0.78718364]\n",
      " [ 0.25918677]\n",
      " [ 0.37537923]\n",
      " [-0.12987533]\n",
      " [-0.05546018]\n",
      " [-0.66038215]\n",
      " [-0.6687969 ]\n",
      " [-1.0280991 ]\n",
      " [-0.53218067]\n",
      " [ 0.2467518 ]\n",
      " [ 1.1227875 ]\n",
      " [ 0.30384436]\n",
      " [ 0.02522245]\n",
      " [-0.48859856]\n",
      " [-0.42239532]\n",
      " [ 0.36435142]\n",
      " [ 1.4500362 ]\n",
      " [-0.01988754]\n",
      " [ 0.4328412 ]\n",
      " [ 0.3866556 ]\n",
      " [ 1.6786865 ]\n",
      " [-1.3454558 ]\n",
      " [-1.7669363 ]\n",
      " [-0.5104464 ]\n",
      " [ 1.7948712 ]\n",
      " [-2.4409838 ]\n",
      " [-1.8206865 ]\n",
      " [ 2.2365696 ]\n",
      " [ 3.258576  ]\n",
      " [ 3.0878754 ]\n",
      " [-3.3476543 ]\n",
      " [-4.1642733 ]\n",
      " [-4.2438583 ]\n",
      " [-3.06979   ]]\n",
      "Round: 40\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008079558280150995\n",
      "2 Fail: due to tiny learning rate( 0.009695469936181193 )\n",
      "Stop, Learning Goal = 1.1520134\n",
      "[[-0.08702925]\n",
      " [ 0.13533619]\n",
      " [ 0.04964131]\n",
      " [-0.53297985]\n",
      " [-0.5658449 ]\n",
      " [-0.7869793 ]\n",
      " [-0.05465996]\n",
      " [ 0.296627  ]\n",
      " [ 0.31068358]\n",
      " [-0.06748191]\n",
      " [-0.61758864]\n",
      " [-0.65673506]\n",
      " [-0.5504017 ]\n",
      " [ 0.31051245]\n",
      " [-1.0735002 ]\n",
      " [ 1.180875  ]\n",
      " [ 0.05315074]\n",
      " [ 0.34301767]\n",
      " [-0.33892217]\n",
      " [-0.4370437 ]\n",
      " [ 1.306662  ]\n",
      " [ 0.5092168 ]\n",
      " [ 0.29073462]\n",
      " [ 0.10260507]\n",
      " [ 0.31082472]\n",
      " [ 1.6331109 ]\n",
      " [-1.2489809 ]\n",
      " [-1.6879398 ]\n",
      " [-0.47897413]\n",
      " [ 1.5992793 ]\n",
      " [-2.3351233 ]\n",
      " [-1.696164  ]\n",
      " [ 2.088718  ]\n",
      " [ 3.0276592 ]\n",
      " [ 2.737714  ]\n",
      " [-3.1304533 ]\n",
      " [-3.9717567 ]\n",
      " [-2.5960858 ]\n",
      " [-3.9995277 ]\n",
      " [-3.072635  ]]\n",
      "Round: 41\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009695469936181193\n",
      "2 Keep learning at learning rate = 0.011634563923417432\n",
      "3 Fail: due to tiny learning rate( 0.008144194746392202 )\n",
      "Stop, Learning Goal = 1.1550843\n",
      "[[-0.03362122]\n",
      " [ 0.05434754]\n",
      " [-0.0203689 ]\n",
      " [ 0.13769624]\n",
      " [-0.5739174 ]\n",
      " [-0.7889024 ]\n",
      " [-0.6023792 ]\n",
      " [-0.6657344 ]\n",
      " [ 0.33975962]\n",
      " [-0.07592258]\n",
      " [ 0.3665903 ]\n",
      " [-0.6694131 ]\n",
      " [ 0.27994224]\n",
      " [-0.31524333]\n",
      " [ 0.05273572]\n",
      " [-1.1027191 ]\n",
      " [-0.4588714 ]\n",
      " [ 1.2322131 ]\n",
      " [ 1.1885582 ]\n",
      " [ 0.35626975]\n",
      " [-0.4050714 ]\n",
      " [ 0.21208134]\n",
      " [ 0.5636134 ]\n",
      " [ 0.18168035]\n",
      " [ 0.21772769]\n",
      " [-1.1856655 ]\n",
      " [ 1.5632809 ]\n",
      " [-1.6687716 ]\n",
      " [-0.46249196]\n",
      " [ 1.4562539 ]\n",
      " [-2.2765872 ]\n",
      " [-1.6576583 ]\n",
      " [ 1.9895041 ]\n",
      " [ 2.8687537 ]\n",
      " [ 2.4966981 ]\n",
      " [-2.996975  ]\n",
      " [-3.8404295 ]\n",
      " [-2.3072104 ]\n",
      " [-3.8678658 ]\n",
      " [-2.8998044 ]\n",
      " [ 3.5150626 ]]\n",
      "Round: 42\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008144194746392202\n",
      "2 Fail: due to tiny learning rate( 0.009773033695670641 )\n",
      "Stop, Learning Goal = 1.1730243\n",
      "[[ 0.02261075]\n",
      " [-0.66584194]\n",
      " [ 0.05689338]\n",
      " [ 0.14435846]\n",
      " [ 0.02830744]\n",
      " [-0.7914554 ]\n",
      " [-0.754624  ]\n",
      " [-0.67459965]\n",
      " [ 0.4294168 ]\n",
      " [ 0.40027806]\n",
      " [-0.12322834]\n",
      " [-0.71774554]\n",
      " [ 0.24460134]\n",
      " [ 1.0073535 ]\n",
      " [-0.287715  ]\n",
      " [ 0.04178295]\n",
      " [-1.1574389 ]\n",
      " [ 0.35961792]\n",
      " [ 1.2770945 ]\n",
      " [-0.36179665]\n",
      " [ 0.096513  ]\n",
      " [-0.3969619 ]\n",
      " [ 0.07641205]\n",
      " [ 0.65170085]\n",
      " [ 0.26997516]\n",
      " [ 1.4238384 ]\n",
      " [-1.0788515 ]\n",
      " [-1.6573336 ]\n",
      " [-0.4706315 ]\n",
      " [ 1.2424066 ]\n",
      " [-2.1911502 ]\n",
      " [-1.5902838 ]\n",
      " [ 2.6726117 ]\n",
      " [ 1.8082991 ]\n",
      " [ 2.1791325 ]\n",
      " [-2.7635918 ]\n",
      " [-1.8882556 ]\n",
      " [-3.6574345 ]\n",
      " [-3.6767948 ]\n",
      " [-2.6687455 ]\n",
      " [ 3.087456  ]\n",
      " [ 4.447319  ]]\n",
      "Round: 43\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009773033695670641\n",
      "2 Keep learning at learning rate = 0.01172764043480477\n",
      "3 Fail: due to tiny learning rate( 0.008209348304363338 )\n",
      "Stop, Learning Goal = 1.157018\n",
      "[[ 0.05373661]\n",
      " [ 0.03550367]\n",
      " [ 0.14647134]\n",
      " [-0.8463802 ]\n",
      " [-0.7376569 ]\n",
      " [-0.78414565]\n",
      " [ 0.39178967]\n",
      " [ 0.05248632]\n",
      " [ 0.8715622 ]\n",
      " [-0.7217863 ]\n",
      " [ 0.4184361 ]\n",
      " [-0.14268951]\n",
      " [-0.25563008]\n",
      " [-0.747732  ]\n",
      " [ 0.2186882 ]\n",
      " [-0.04535227]\n",
      " [ 0.01217385]\n",
      " [-1.2555283 ]\n",
      " [ 0.38416332]\n",
      " [ 1.3388997 ]\n",
      " [-0.41882467]\n",
      " [-0.30988818]\n",
      " [-0.04771964]\n",
      " [ 1.311775  ]\n",
      " [ 0.716018  ]\n",
      " [-1.0279372 ]\n",
      " [ 0.2867028 ]\n",
      " [-1.6241672 ]\n",
      " [ 1.1047196 ]\n",
      " [-0.4729576 ]\n",
      " [-2.131358  ]\n",
      " [-1.550451  ]\n",
      " [ 2.5498102 ]\n",
      " [ 1.6861023 ]\n",
      " [ 1.9266248 ]\n",
      " [-1.5940745 ]\n",
      " [-2.6139133 ]\n",
      " [-3.5480807 ]\n",
      " [-3.5410407 ]\n",
      " [ 2.832009  ]\n",
      " [-2.51887   ]\n",
      " [ 4.2060766 ]\n",
      " [ 2.6098468 ]]\n",
      "Round: 44\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008209348304363338\n",
      "2 Fail: due to tiny learning rate( 0.009851217965236006 )\n",
      "Stop, Learning Goal = 1.1616721\n",
      "[[ 0.6483463 ]\n",
      " [ 0.15649948]\n",
      " [-0.9360378 ]\n",
      " [ 0.02355042]\n",
      " [ 0.10949995]\n",
      " [-0.71874297]\n",
      " [-0.78698313]\n",
      " [ 0.09892419]\n",
      " [ 0.3888308 ]\n",
      " [-0.7628907 ]\n",
      " [-0.19087067]\n",
      " [ 0.46165118]\n",
      " [-0.185774  ]\n",
      " [-0.07406822]\n",
      " [-0.79658926]\n",
      " [ 0.19705972]\n",
      " [-0.12604252]\n",
      " [ 0.45019373]\n",
      " [-0.41309264]\n",
      " [-1.3226761 ]\n",
      " [ 1.4148372 ]\n",
      " [-0.20624068]\n",
      " [-0.23503998]\n",
      " [ 1.1745425 ]\n",
      " [-0.95242846]\n",
      " [ 0.8150885 ]\n",
      " [-1.5677198 ]\n",
      " [ 0.33896574]\n",
      " [ 0.96350384]\n",
      " [-0.44521293]\n",
      " [-2.0391843 ]\n",
      " [-1.4835596 ]\n",
      " [ 2.35212   ]\n",
      " [ 1.5700914 ]\n",
      " [ 1.5391463 ]\n",
      " [-1.2017815 ]\n",
      " [-2.3818214 ]\n",
      " [-3.3852613 ]\n",
      " [-3.3606553 ]\n",
      " [ 2.4999638 ]\n",
      " [ 2.0201938 ]\n",
      " [ 3.9020824 ]\n",
      " [-2.3036213 ]\n",
      " [-2.6779842 ]]\n",
      "Round: 45\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009851217965236006\n",
      "2 Keep learning at learning rate = 0.011821461558283208\n",
      "3 Fail: due to tiny learning rate( 0.008275023090798245 )\n",
      "Stop, Learning Goal = 1.1455123\n",
      "[[ 0.17497355]\n",
      " [-0.7017969 ]\n",
      " [ 0.01824808]\n",
      " [ 0.13445574]\n",
      " [-0.98578775]\n",
      " [ 0.51869357]\n",
      " [-0.8268194 ]\n",
      " [ 0.39665562]\n",
      " [ 0.12578619]\n",
      " [-0.14869058]\n",
      " [-0.10862863]\n",
      " [-0.81804883]\n",
      " [ 0.48930895]\n",
      " [-0.20601702]\n",
      " [ 0.18095064]\n",
      " [-0.79246783]\n",
      " [-0.30741996]\n",
      " [-0.40014738]\n",
      " [-0.1522497 ]\n",
      " [ 0.47713697]\n",
      " [-1.3662726 ]\n",
      " [ 1.46942   ]\n",
      " [ 1.0983704 ]\n",
      " [-0.17433506]\n",
      " [-0.8861097 ]\n",
      " [ 0.86467373]\n",
      " [-1.5340325 ]\n",
      " [ 0.8712026 ]\n",
      " [ 0.37284386]\n",
      " [-0.42779434]\n",
      " [ 1.3563833 ]\n",
      " [-1.9804603 ]\n",
      " [ 2.2418127 ]\n",
      " [-0.9591826 ]\n",
      " [ 1.4450912 ]\n",
      " [-1.443365  ]\n",
      " [-2.239965  ]\n",
      " [-3.258206  ]\n",
      " [ 1.6958091 ]\n",
      " [ 2.29077   ]\n",
      " [-3.2342415 ]\n",
      " [ 3.7107277 ]\n",
      " [-2.1391706 ]\n",
      " [-2.5251498 ]\n",
      " [-2.779304  ]]\n",
      "Round: 46\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008275023090798245\n",
      "2 Fail: due to tiny learning rate( 0.009930027708957893 )\n",
      "Stop, Learning Goal = 1.1500843\n",
      "[[ 0.19370404]\n",
      " [-0.6979927 ]\n",
      " [-0.02177915]\n",
      " [ 0.19265027]\n",
      " [ 0.40176636]\n",
      " [-1.058414  ]\n",
      " [-0.13408181]\n",
      " [-0.8866526 ]\n",
      " [-0.1865252 ]\n",
      " [ 0.16746047]\n",
      " [ 0.3329505 ]\n",
      " [-0.4341167 ]\n",
      " [-0.8927103 ]\n",
      " [ 0.50432706]\n",
      " [-0.23089573]\n",
      " [-0.7835543 ]\n",
      " [ 0.16646066]\n",
      " [-0.3668783 ]\n",
      " [-0.16543743]\n",
      " [ 0.49324146]\n",
      " [ 0.9731916 ]\n",
      " [-1.4057102 ]\n",
      " [ 1.5397564 ]\n",
      " [-0.08376029]\n",
      " [-0.8213569 ]\n",
      " [ 0.7180525 ]\n",
      " [-1.5065618 ]\n",
      " [ 0.94468737]\n",
      " [ 0.39372197]\n",
      " [ 1.033724  ]\n",
      " [-0.40231225]\n",
      " [-0.64305353]\n",
      " [ 2.0765283 ]\n",
      " [-1.8972567 ]\n",
      " [ 1.3075588 ]\n",
      " [-1.387487  ]\n",
      " [-2.048639  ]\n",
      " [ 1.255115  ]\n",
      " [-3.078929  ]\n",
      " [ 1.9878082 ]\n",
      " [-3.0483508 ]\n",
      " [ 3.4344976 ]\n",
      " [-1.9132847 ]\n",
      " [-2.305936  ]\n",
      " [-2.456802  ]\n",
      " [ 4.146132  ]]\n",
      "Round: 47\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.009930027708957893\n",
      "2 Keep learning at learning rate = 0.011916033250749471\n",
      "3 Fail: due to tiny learning rate( 0.00834122327552463 )\n",
      "Stop, Learning Goal = 1.1407568\n",
      "[[ 0.18901482]\n",
      " [-0.6898985 ]\n",
      " [-0.08055535]\n",
      " [-0.25917092]\n",
      " [ 0.3966485 ]\n",
      " [-0.15932122]\n",
      " [ 0.2491149 ]\n",
      " [-0.49573448]\n",
      " [-1.0841587 ]\n",
      " [-0.8984126 ]\n",
      " [ 0.1896309 ]\n",
      " [ 0.5182673 ]\n",
      " [-0.7977475 ]\n",
      " [-0.25902906]\n",
      " [ 0.17192087]\n",
      " [-0.9186653 ]\n",
      " [ 0.21595797]\n",
      " [ 0.8934479 ]\n",
      " [-0.3590429 ]\n",
      " [-0.17672363]\n",
      " [ 0.5103549 ]\n",
      " [-1.434583  ]\n",
      " [-0.8091264 ]\n",
      " [ 0.6121087 ]\n",
      " [ 1.5906261 ]\n",
      " [-0.03970447]\n",
      " [ 0.82431936]\n",
      " [-1.4841264 ]\n",
      " [-0.4654241 ]\n",
      " [ 0.37959632]\n",
      " [ 0.9757556 ]\n",
      " [-0.38447002]\n",
      " [ 1.9734405 ]\n",
      " [-1.8455418 ]\n",
      " [ 1.2406199 ]\n",
      " [-1.335209  ]\n",
      " [ 0.9815252 ]\n",
      " [-1.9327112 ]\n",
      " [-2.9712403 ]\n",
      " [ 1.8077258 ]\n",
      " [-2.946899  ]\n",
      " [ 3.2664924 ]\n",
      " [-1.7930225 ]\n",
      " [-2.277557  ]\n",
      " [-2.165747  ]\n",
      " [ 3.8656569 ]\n",
      " [ 3.2640836 ]]\n",
      "Round: 48\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.00834122327552463\n",
      "2 Keep learning at learning rate = 0.010009467930629555\n",
      "3 Fail: due to tiny learning rate( 0.007006627551440688 )\n",
      "Stop, Learning Goal = 1.1729932\n",
      "[[ 1.8271518e-01]\n",
      " [-6.9397068e-01]\n",
      " [-3.6021042e-01]\n",
      " [-1.5373683e-01]\n",
      " [ 3.7664473e-01]\n",
      " [-5.4838729e-01]\n",
      " [-1.8492341e-01]\n",
      " [ 3.0874127e-01]\n",
      " [-1.1324623e+00]\n",
      " [-9.2245412e-01]\n",
      " [ 2.1924108e-01]\n",
      " [ 5.3244758e-01]\n",
      " [-8.4160852e-01]\n",
      " [ 1.6101658e-01]\n",
      " [ 8.1650376e-01]\n",
      " [-2.8868949e-01]\n",
      " [-9.3413210e-01]\n",
      " [-3.6720878e-01]\n",
      " [ 1.0344005e-01]\n",
      " [-1.9570327e-01]\n",
      " [ 4.9352527e-01]\n",
      " [ 5.1270640e-01]\n",
      " [-7.9584432e-01]\n",
      " [-1.4910196e+00]\n",
      " [ 6.2447453e-01]\n",
      " [ 1.6078783e+00]\n",
      " [-1.4167130e-03]\n",
      " [-2.5448346e-01]\n",
      " [-1.4911933e+00]\n",
      " [ 3.6228538e-01]\n",
      " [ 1.9008965e+00]\n",
      " [-3.7792730e-01]\n",
      " [ 1.0073898e+00]\n",
      " [-1.7892458e+00]\n",
      " [ 1.1639835e+00]\n",
      " [ 6.9354939e-01]\n",
      " [-1.2559793e+00]\n",
      " [-1.8085001e+00]\n",
      " [-2.8651214e+00]\n",
      " [ 1.6337183e+00]\n",
      " [-2.8381226e+00]\n",
      " [ 3.0581138e+00]\n",
      " [-1.6894346e+00]\n",
      " [ 3.5708468e+00]\n",
      " [-2.1025774e+00]\n",
      " [-2.0411856e+00]\n",
      " [ 2.9794738e+00]\n",
      " [ 5.3024235e+00]]\n",
      "Round: 49\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007006627551440688\n",
      "2 Fail: due to tiny learning rate( 0.008407953061728824 )\n",
      "Stop, Learning Goal = 1.1967918\n",
      "[[ 1.7042863e-01]\n",
      " [-6.9662797e-01]\n",
      " [-5.1781881e-01]\n",
      " [-5.8940601e-01]\n",
      " [ 3.2816339e-01]\n",
      " [-2.0923817e-01]\n",
      " [-2.4132723e-01]\n",
      " [ 4.1629279e-01]\n",
      " [-9.2563760e-01]\n",
      " [-1.2098438e+00]\n",
      " [ 2.6518747e-01]\n",
      " [ 7.2448838e-01]\n",
      " [ 4.9728227e-01]\n",
      " [ 1.2713963e-01]\n",
      " [-8.8505340e-01]\n",
      " [-3.0555022e-01]\n",
      " [-9.9296629e-01]\n",
      " [ 3.6359334e-01]\n",
      " [ 3.7452680e-01]\n",
      " [-3.6083281e-01]\n",
      " [ 4.2949092e-01]\n",
      " [-2.1355784e-01]\n",
      " [-4.9056172e-02]\n",
      " [-8.1292939e-01]\n",
      " [ 2.4648130e-02]\n",
      " [-1.5440085e+00]\n",
      " [ 1.6213619e+00]\n",
      " [ 4.6015680e-03]\n",
      " [-1.5137693e+00]\n",
      " [ 1.8398792e+00]\n",
      " [ 2.8797007e-01]\n",
      " [ 3.2653022e-01]\n",
      " [-3.4505093e-01]\n",
      " [ 1.0135568e+00]\n",
      " [ 1.0686667e+00]\n",
      " [-1.6937977e+00]\n",
      " [-1.1516467e+00]\n",
      " [-1.6469787e+00]\n",
      " [ 1.4055587e+00]\n",
      " [-2.7225466e+00]\n",
      " [ 2.7788596e+00]\n",
      " [-2.7015581e+00]\n",
      " [-1.5911406e+00]\n",
      " [ 3.1357403e+00]\n",
      " [-1.8854865e+00]\n",
      " [-1.8880590e+00]\n",
      " [ 2.5672259e+00]\n",
      " [ 4.8524761e+00]\n",
      " [ 5.0319347e+00]]\n",
      "Round: 50\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.008407953061728824\n",
      "2 Keep learning at learning rate = 0.010089543674074589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Fail: due to tiny learning rate( 0.007062680571852211 )\n",
      "Stop, Learning Goal = 1.1950259\n",
      "[[-6.38672829e-01]\n",
      " [ 1.87388808e-01]\n",
      " [-5.86775661e-01]\n",
      " [-5.89699149e-01]\n",
      " [ 3.41550469e-01]\n",
      " [-2.13287085e-01]\n",
      " [ 6.60866141e-01]\n",
      " [ 2.14083105e-01]\n",
      " [-9.05339956e-01]\n",
      " [-2.74055928e-01]\n",
      " [ 4.90388423e-01]\n",
      " [ 3.08227509e-01]\n",
      " [-1.21918929e+00]\n",
      " [ 4.91917342e-01]\n",
      " [ 3.21739435e-01]\n",
      " [ 1.80004388e-01]\n",
      " [ 1.43338650e-01]\n",
      " [-3.03427666e-01]\n",
      " [-9.26719546e-01]\n",
      " [-1.00967205e+00]\n",
      " [ 4.23609167e-01]\n",
      " [-3.51471156e-01]\n",
      " [-1.91241235e-01]\n",
      " [-8.01235080e-01]\n",
      " [-1.49536312e+00]\n",
      " [-1.53900951e-01]\n",
      " [ 1.23756796e-01]\n",
      " [ 1.62165987e+00]\n",
      " [ 1.38866901e-03]\n",
      " [-1.50927913e+00]\n",
      " [ 1.81945920e+00]\n",
      " [ 2.43244678e-01]\n",
      " [-3.25234622e-01]\n",
      " [ 1.02295041e+00]\n",
      " [-1.62976861e+00]\n",
      " [ 1.02007926e+00]\n",
      " [-1.09626997e+00]\n",
      " [-1.53678787e+00]\n",
      " [ 1.26402259e+00]\n",
      " [-2.61220336e+00]\n",
      " [ 2.61188769e+00]\n",
      " [-2.63299632e+00]\n",
      " [ 2.86523771e+00]\n",
      " [-1.51309061e+00]\n",
      " [-1.78362310e+00]\n",
      " [-1.74253929e+00]\n",
      " [ 2.31282139e+00]\n",
      " [ 4.58709002e+00]\n",
      " [ 4.82632446e+00]\n",
      " [-3.57375669e+00]]\n",
      "Round: 51\n",
      "Out-lier detection!\n",
      "1 Keep learning at learning rate = 0.007062680571852211\n",
      "2 Fail: due to tiny learning rate( 0.008475216686222654 )\n",
      "Stop, Learning Goal = 1.2115319\n",
      "[[ 0.1792151 ]\n",
      " [-0.5633645 ]\n",
      " [-0.60052776]\n",
      " [ 0.01980856]\n",
      " [ 0.57510483]\n",
      " [ 0.33919147]\n",
      " [-0.68439317]\n",
      " [-0.2307665 ]\n",
      " [-0.89884996]\n",
      " [ 0.37074807]\n",
      " [-0.3198295 ]\n",
      " [ 0.4530491 ]\n",
      " [ 0.25352108]\n",
      " [-1.2466214 ]\n",
      " [ 0.29687256]\n",
      " [ 0.15231106]\n",
      " [-0.32659063]\n",
      " [ 0.55845857]\n",
      " [-0.9681115 ]\n",
      " [ 0.4373701 ]\n",
      " [-1.0179081 ]\n",
      " [-0.3572758 ]\n",
      " [-0.21071956]\n",
      " [-0.18104205]\n",
      " [-0.7437092 ]\n",
      " [-1.4519467 ]\n",
      " [ 1.5449744 ]\n",
      " [-0.02481553]\n",
      " [-0.26977608]\n",
      " [-1.4578753 ]\n",
      " [ 1.791175  ]\n",
      " [ 0.19886866]\n",
      " [-0.30831382]\n",
      " [-1.5173333 ]\n",
      " [ 0.91447806]\n",
      " [-1.3821359 ]\n",
      " [ 1.068101  ]\n",
      " [-1.0412203 ]\n",
      " [ 1.0906866 ]\n",
      " [-2.4115503 ]\n",
      " [ 2.3461943 ]\n",
      " [ 2.4951134 ]\n",
      " [-2.5243702 ]\n",
      " [-1.3699175 ]\n",
      " [-1.6257365 ]\n",
      " [-1.5828955 ]\n",
      " [ 1.9874499 ]\n",
      " [ 4.18693   ]\n",
      " [ 4.5548463 ]\n",
      " [-3.1722717 ]\n",
      " [ 5.088317  ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter(\"./showmethetensorboard\", sess.graph)\n",
    "sess.run(init)\n",
    "\n",
    "#Step1. Pick up n cases to set up an acceptable SLFN with 1 hidden node\n",
    "n = 1\n",
    "lts_x_error = sess.run(residual, feed_dict={xs: x_data, yc: y_data})\n",
    "Output = sess.run(OutputLOutput, feed_dict={xs: x_data, yc: y_data})\n",
    "lts_x_data, lts_y_data = lts(n, lts_x_error, x_data, y_data)\n",
    "print(\"Round:\", n, \"\\nInitial model.\")\n",
    "n = n + 1\n",
    "\n",
    "#Step1.1 Initial SLFN model\n",
    "sess.run(train, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "Output = sess.run(OutputLOutput, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "Error = sess.run(LossFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "iniHWeights = sess.run(HWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "iniHThreshold = sess.run(HThreshold, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "iniOWeights = sess.run(OWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "iniOThreshold = sess.run(OThreshold, feed_dict={xs: lts_x_data, yc: lts_y_data}) \n",
    "\n",
    "#Step2. Add another case into I(n)\n",
    "  #Stopping Criteria1: n = dataVolume\n",
    "while n <= dataVolume:\n",
    "    #Save previous error, weights & thresholds\n",
    "    preError = Error\n",
    "    preHWeights = sess.run(HWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "    preHThreshold = sess.run(HThreshold, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "    preOWeights = sess.run(OWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "    preOThreshold = sess.run(OThreshold, feed_dict={xs: lts_x_data, yc: lts_y_data})    \n",
    "    lts_x_error = sess.run(residual, feed_dict={xs: x_data, yc: y_data})\n",
    "    lts_x_data, lts_y_data = lts(n, lts_x_error, x_data, y_data)\n",
    "    #debugging\n",
    "    print(\"Round:\", n)\n",
    "    #print(lts_x_data)\n",
    "    #print(lts_y_data)\n",
    "    #print(preError, preHThreshold, preHWeights, preOThreshold, preOWeights, sep = \"\\n\")\n",
    "    n = n + 1\n",
    "\n",
    "#Step3. Whether I(n) satisfying the Learning Goal?\n",
    "    LearningGoal = sess.run(LearningGoalFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "    #Stopping Criteria2: LearningGoal <= 0.1\n",
    "    if LearningGoal <= 0.1:\n",
    "        print(\"No out-lier.\")\n",
    "        continue\n",
    "        \n",
    "#Step4. Weight-Tuning Mechanism: Creating a new SLFN model\n",
    "    else:\n",
    "        print(\"Out-lier detection!\")\n",
    "        time = 0\n",
    "        #Step5-1. Stopping Criteria(1): LearningGoal <= 0.1\n",
    "        while LearningGoal > 0.1:\n",
    "            time = time + 1\n",
    "            #train a new model\n",
    "            sess.run(train, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "            Output = sess.run(OutputLOutput, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "            if Error > preError:\n",
    "\n",
    "        #Step5-2. Stopping Criteria(2): Learning-rate\n",
    "                if LearningRate < 0.01:\n",
    "                    print(time, \"Fail: due to tiny learning rate(\", LearningRate, \")\")\n",
    "                    #restore weights & thresholds (Step.6 Cramming & Softening Mechanism... to be updated)\n",
    "                    #sess.run(tf.assign(HWeights, iniHWeights))\n",
    "                    #sess.run(tf.assign(HThreshold, iniHThreshold))\n",
    "                    #sess.run(tf.assign(OWeights, iniOWeights))\n",
    "                    #sess.run(tf.assign(OThreshold, iniOThreshold)) \n",
    "                    break\n",
    "                else:\n",
    "                    print(time, \"Keep learning at learning rate =\", LearningRate)\n",
    "                    LearningRate = LearningRate * 0.7\n",
    "                    sess.run(tf.assign(HWeights, preHWeights))\n",
    "                    sess.run(tf.assign(HThreshold, preHThreshold))\n",
    "                    sess.run(tf.assign(OWeights, preOWeights))\n",
    "                    sess.run(tf.assign(OThreshold, preOThreshold)) \n",
    "\n",
    "            else:\n",
    "                print(time, \"Keep learning at learning rate =\", LearningRate)\n",
    "                LearningRate = LearningRate * 1.2\n",
    "                Error = sess.run(LossFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        print(\"Stop, Learning Goal =\", LearningGoal)\n",
    "        sess.run(train, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        Output = sess.run(OutputLOutput, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        Error = sess.run(LossFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        LearningGoal = sess.run(LearningGoalFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        print(Output)\n",
    "        \n",
    "            #debugging\n",
    "        #Weights = sess.run(OWeights, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        #LearningGoal = sess.run(LearningGoalFunction, feed_dict={xs: lts_x_data, yc: lts_y_data})\n",
    "        #LearningRateArr.append(LearningRate)\n",
    "        #ErrorArr.append(Error)\n",
    "        #print(\"Time =\", time, \" Learning Rate =\", LearningRate, \" Error =\", Error)\n",
    "        #print(\"Weights =\", Weights)\n",
    "        #print(\"Output =\", Output)\n",
    "        #LearningRateGraph = plt.plot(LearningRateArr)\n",
    "        #print(\"Learning Rate\", LearningRateGraph)\n",
    "        #ErrorGraph = plt.plot(ErrorArr)\n",
    "        #print(\"Error\", ErrorGraph)\n",
    "\n",
    "writer.close()\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go to Terminal\n",
    "#enter:\n",
    "    #cd ~user\n",
    "    #tensorboard --logdir=showmethetensorboard --host=127.0.0.1\n",
    "#Copy the URL to your browser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
